{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). On JupyterLab, you may want to hit the \"Validate\" button as well.\n",
    "\n",
    "Caution: do not mess with the notebook's metadata; do not change a pre-existing cell's type; do not copy pre-existing cells (add new ones with the + button instead). This will break autograding; you will get a 0; you are warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%; border: none;\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
    "  <tr>\n",
    "    <td><img src=\"https://www.planetegrandesecoles.com/wp-content/uploads/2021/07/Identite%CC%81-visuelle-Plane%CC%80te-BAC-8-600x398.png\" style=\"float: left; width: 100%\" />\n",
    "</td>\n",
    "    <td><a style=\"font-size: 3em; text-align: center; vertical-align: middle;\" href=\"https://moodle.polytechnique.fr/course/view.php?id=19260\">[CSC2S004EP - 2024] - Introduction to Machine Learning</a>\n",
    "</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd6ebd5d9ca397a7610fd4bbaeb01e04",
     "grade": false,
     "grade_id": "cell-af5a035c54cd45c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "meta",
     "toc_en"
    ],
    "toc-hr-collapsed": false
   },
   "source": [
    "<a style=\"font-size: 3em;\">Lab Session 2: parametric models</a>\n",
    "\n",
    "Jérémie DECOCK - Adrien EHRHARDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d1bf67722b9ae1cda084534facdc3f2",
     "grade": false,
     "grade_id": "cell-8936d2d1fab8ae72",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "- Introduction to parametric models for regression: we assume a particular form in the relationship of $\\boldsymbol{x}$ to $y$.\n",
    "- Calculate by hand a linear regression: what is the \"closest line\" to my data points?\n",
    "- Implement a linear regressor using gradient descent: implement a method so as to make the computer iteratively find that \"closest line\".\n",
    "- Linear regression with Scikit Learn: there's a catch -> \"someone\" already did that (obviously)!\n",
    "- Implement a polynomial regressor with Scikit Learn: that \"someone\" implemented even cleverer methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "efd4368576813795d809006638b30e95",
     "grade": false,
     "grade_id": "cell-e93c2d0251fc72af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Imports and tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f1410363268b8114cbf3d76107cf7f1",
     "grade": false,
     "grade_id": "cell-a6a109c8cb7dee00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b88639816176e92c03a25e1c6a0a02af",
     "grade": false,
     "grade_id": "cell-9d5f4be4f91fc6ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Read carefully** the function definitions below (especially the two first ones); we'll use them to generate and plot some data which will be the subject of subsequent questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "901458456f56e5178ea97bc78e244b44",
     "grade": false,
     "grade_id": "cell-5485a9ef4d7f6996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generate some fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3df861cbad253c19863d6e3591030aca",
     "grade": false,
     "grade_id": "cell-6656a058fae3c466",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_1d_linear_regression_samples(n_samples: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate one-dimensional linear regression samples\n",
    "\n",
    "    :param int n_samples: number of samples to generate\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=-8., high=8., size=n_samples)\n",
    "    y = 2. * x - 3. + np.random.normal(scale=1.5, size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def gen_1d_polynomial_regression_samples(n_samples: int = 15) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate one-dimensional polynomial regression samples\n",
    "\n",
    "    :param int n_samples: number of samples to generate\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=-5., high=5., size=n_samples)\n",
    "    y = -4. + 2 * x + 0.7 * x ** 2 - 1.5 * x ** 3 + np.random.normal(scale=8., size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df = sklearn.utils.shuffle(df).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e301a65aa12ac91a6088922522181e81",
     "grade": false,
     "grade_id": "cell-16a2c3ba9fae513e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07a50f00220251a803b01e193a72b38e",
     "grade": false,
     "grade_id": "cell-b5a6dfcd278ff25e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_XY(X: np.array, y: np.array):\n",
    "    \"\"\"\n",
    "    Puts X and y in a dataframe and plot the result; expects one-dimensional inputs X and y.\n",
    "    If theta_0 and theta_1 are provided, calculate and plot y_hat as well.\n",
    "\n",
    "    :param numpy.array X: one-dimensional regression feature\n",
    "    :param numpy.array y: one-dimensional target feature\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.array([X, y]).T, columns=['x', 'y'])\n",
    "    ax = df.plot.scatter(x=\"x\", y=\"y\")\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_1d_regression_samples(dataframe: pd.DataFrame, model=None):\n",
    "    \"\"\"\n",
    "    Plot the regression samples in one-D with the predictions if model is provided\n",
    "\n",
    "    :param pandas.DataFrame dataframe: a dataframe containing the :code:`x` feature and\n",
    "        :code:`y` dependent feature to regress on.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    df = dataframe.copy()  # make an alias\n",
    "\n",
    "    ERROR_MSG1 = \"The `dataframe` parameter should be a Pandas DataFrame having the following columns: ['x', 'y']\"\n",
    "    assert df.columns.values.tolist() == ['x', 'y'], ERROR_MSG1\n",
    "\n",
    "    if model is not None:\n",
    "        # Compute the model's prediction\n",
    "        x_pred = np.linspace(df.x.min(), df.x.max(), 100).reshape(-1, 1)\n",
    "        y_pred = model.predict(pd.DataFrame(x_pred, columns=['x']))\n",
    "        df_pred = pd.DataFrame(np.array([x_pred.flatten(), y_pred.flatten()]).T, columns=['x', 'y'])\n",
    "        df_pred.plot(x='x', y='y', style='r--', ax=ax)\n",
    "\n",
    "    # Plot also the training points\n",
    "    df.plot.scatter(x='x', y='y', ax=ax)\n",
    "    delta_y = df.y.max() - df.y.min()\n",
    "    plt.ylim((df.y.min() - 0.15 * delta_y,\n",
    "              df.y.max() + 0.15 * delta_y))\n",
    "\n",
    "\n",
    "def plot_ex4(X: np.array, y: np.array, theta_1: float = None, theta_2: float = None):\n",
    "    \"\"\"\n",
    "    Puts X and y in a dataframe and plot the result; expects one-dimensional inputs X and y.\n",
    "    If theta_1 and theta_2 are provided, calculate and plot y_hat = theta_1 * x + theta_2 * x**2 as well.\n",
    "\n",
    "    :param numpy.array X: one-dimensional regression feature\n",
    "    :param numpy.array y: one-dimensional target feature\n",
    "    :param float theta_1: linear regression coefficient associated with X\n",
    "    :param float theta_2: linear regression coefficient associated with X**2\n",
    "    \"\"\"\n",
    "    ax = plot_XY(X, y)\n",
    "\n",
    "    if theta_1 is not None and theta_2 is not None:\n",
    "        x = np.linspace(0, 6, 50)\n",
    "        y = theta_1 * x + theta_2 * x**2\n",
    "        ax.plot(x, y, \"--r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0016d7099525733c884c1e32c727a4ca",
     "grade": false,
     "grade_id": "cell-be70105c106f3c0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1d2e1d41e2fa94aed42347021f0b7f7",
     "grade": false,
     "grade_id": "cell-c85056646ced4537",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Today you will learn to solve *regression* problems using **parametric models** (the application of parametric models to *classification* problems will be the subject of another session): you will use a parametric function $f_{\\boldsymbol{\\theta}}: \\boldsymbol{x} \\mapsto y$ to infer the link existing between input vectors $\\boldsymbol{x} \\in \\mathbb{R}^p$ and output values $y \\in \\mathbb{R}$ in a *learning set* $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$ of $n$ examples.\n",
    "\n",
    "The *hypothesis space* $\\mathcal{H}$ of $f_{\\boldsymbol{\\theta}}$ is chosen *a priori*, so that the model fits reasonably well the data in $\\mathcal{D}$. For instance, $\\mathcal{H}$ can be the space of linear functions if the data seems to be distributed along a line in $\\mathcal{D}$. The space of polynomial functions of degree $d>1$ may be a good choice otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d8fcdbea09dd6d12a6adab943d9b804",
     "grade": false,
     "grade_id": "cell-495715032500736b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The parameter $\\boldsymbol{\\theta}^* = \\begin{pmatrix} \\theta_0^* & \\dots & \\theta_p^* \\end{pmatrix}^T$ is then searched to obtain the best fit between $f_{\\boldsymbol{\\theta}}$ and $\\mathcal{D}$. This is an optimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57c3a42f6dae1e2377364731debb07d8",
     "grade": false,
     "grade_id": "cell-d638b5451d2cc97c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For instance, assume you have chosen the space of linear functions to make a model that describes the data in $\\mathcal{D}$, and $p=1$ (one-dimensional regression).\n",
    "\n",
    "Your model is then $y = \\theta_0 + \\theta_1 x$ and the regression problem consists in finding the best parameters (strictly speaking, estimators of these parameters) $\\theta_0^\\star$ and $\\theta_1^\\star$ for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a49474732a451cda53de06e6c41e5ee2",
     "grade": false,
     "grade_id": "cell-105796cda48284cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: there are some differences in notations with the lecture slides: parameters are noted $w$ (for \"weights\": machine learning community) in lectures but they are noted $\\theta$ (for parameters: statistics community) here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "571251ab624c83a7b6d80d5b46423e15",
     "grade": false,
     "grade_id": "cell-effda178ed28f9a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Linear regression: an analytic definition of the optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ea11488661142e8595889c4e5b9e37b",
     "grade": false,
     "grade_id": "cell-9e460f50efcfb03c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have a *learning set* $\\mathcal{D} = \\{(\\boldsymbol{x^{(i)}}, y^{(i)})\\}_{1 \\leq i \\leq n}$.\n",
    "\n",
    "We assume:\n",
    "- Errors (difference between actual labels $y$ and predicted labels $\\hat{y} = f_{\\theta}(\\boldsymbol{x})$) are gaussian random values centered at 0: $y = f_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n",
    "- Data is modeled with a linear function: $f_{\\boldsymbol{\\theta}}(\\boldsymbol{x}) = \\theta_0 + \\sum_{j=1}^p \\theta_j \\boldsymbol{x}_j = (1 \\; x)^T \\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddac588d25e65304a0fd4d7b0379a43d",
     "grade": false,
     "grade_id": "cell-9f12cf6556b45692",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Observations $\\boldsymbol{x} \\in \\mathbb{R}^p$ can be defined as $p$ random values $X_1, X_2, \\dots, X_p$\n",
    "- Labels $y$ are then realizations of a random value $Y$ such that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53d57619ca548009c952784563d6522c",
     "grade": false,
     "grade_id": "cell-9653f671cc4f867e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$$Y \\sim \\mathcal{N}(\\underbrace{f(\\boldsymbol{x} | \\boldsymbol{\\theta})}_{\\mu}, \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6cbac106d1bf80cd0771a6340ce05fe",
     "grade": false,
     "grade_id": "cell-df29b0d7ce3ee807",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to find the estimator $\\boldsymbol{\\theta}^* = \\begin{pmatrix} \\theta_0^* & \\dots & \\theta_p^* \\end{pmatrix}^T$ that gives the best fit between $f_{\\boldsymbol{\\theta}}$ and $\\mathcal{D}$ (optimization problem).\n",
    "\n",
    "Finding the best $\\boldsymbol{\\theta}^*$ is a maximum likelihood problem : $\\boldsymbol{\\theta}^* \\leftarrow {\\arg\\!\\max}_{\\boldsymbol{\\theta}} \\mathbb{P}(\\mathcal{D}|\\boldsymbol{\\theta})$.\n",
    "Here, it is equivalent to apply the method of *least squares* or to minimize the Mean Square Error (MSE).\n",
    "Using matrix notation, we define the linear regression problem as:\n",
    "\n",
    "$$\\boldsymbol{\\theta}^* \\leftarrow {\\arg\\!\\min}_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta}) \\quad \\text{with} \\quad E(\\boldsymbol{\\theta}) = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})^T(\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71c85b5168c21963e86829f7524c4570",
     "grade": false,
     "grade_id": "cell-61475c62d66cbf76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "and\n",
    "\n",
    "$$\n",
    "\\boldsymbol{X} = \\begin{pmatrix} 1 & x_1^{(1)} & \\dots & x_p^{(1)} \\\\ \\vdots & \\vdots & \\dots & \\vdots \\\\ 1 & x_1^{(n)} & \\dots & x_p^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{y} = \\begin{pmatrix} y^{(1)} \\\\ \\vdots \\\\ y^{(n)} \\end{pmatrix}\n",
    "\\quad \\quad\n",
    "\\boldsymbol{\\theta} = \\begin{pmatrix} \\theta_0 \\\\ \\vdots \\\\ \\theta_p \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "$E(\\boldsymbol{\\theta})$ is a quadratic form (convex function) thus it has a unique global minimum $\\boldsymbol{\\theta^*}$ where $\\nabla_{\\boldsymbol{\\theta^*}} E(\\boldsymbol{\\theta^*}) = \\boldsymbol{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b83c3e5eefb021b01d400c07c2470918",
     "grade": false,
     "grade_id": "cell-b82ff7d33e4f9d19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1 - the theory\n",
    "\n",
    "In the cell below or on a sheet of paper that you can insert as image (New Cell > Markdown > Edit > Insert Image):\n",
    "- Compute the analytic formulation of the gradient $\\nabla_{\\boldsymbol{\\theta}} E(\\boldsymbol{\\theta})$ of the residual sum of squares $E(\\boldsymbol{\\theta}) = (\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})^T(\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\theta})$\n",
    "- Compute the analytic formulation of the optimal parameter $\\boldsymbol{\\theta^*}$\n",
    "\n",
    "You can first use $p=1$, but with a greater value of $p$, matrix notation (and calculus) will come in handy.\n",
    "\n",
    "You may use your lecture notes, but do not copy-paste blindly; this exercise is here for you as it's important to remember these things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "167ca9509005f494c3361dec09c4cee7",
     "grade": false,
     "grade_id": "cell-0afe21ded2af0a54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall about matrices:\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{A} + \\boldsymbol{B})^T = \\boldsymbol{A}^T + \\boldsymbol{B}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\boldsymbol{A} \\boldsymbol{B})^T = \\boldsymbol{B}^T \\boldsymbol{A}^T\n",
    "$$\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Associativity:} & \\quad\n",
    "(\\boldsymbol{A} \\boldsymbol{B}) \\boldsymbol{C}\n",
    "= \\boldsymbol{A} (\\boldsymbol{B} \\boldsymbol{C})\n",
    "= \\boldsymbol{A} \\boldsymbol{B} \\boldsymbol{C}\n",
    "\\\\\n",
    "\\text{Non-commutativity:} & \\quad\n",
    "\\boldsymbol{A} \\boldsymbol{B}\n",
    "\\neq \\boldsymbol{B} \\boldsymbol{A}\n",
    "\\\\\n",
    "\\text{Distributivity:} & \\quad\n",
    "\\boldsymbol{A} (\\boldsymbol{B} + \\boldsymbol{C})\n",
    "= \\boldsymbol{A} \\boldsymbol{B} + \\boldsymbol{A} \\boldsymbol{C} \\\\\n",
    "& \\quad\n",
    "(\\boldsymbol{B} + \\boldsymbol{C}) \\boldsymbol{A} \n",
    "= \\boldsymbol{B} \\boldsymbol{A} + \\boldsymbol{C} \\boldsymbol{A}\n",
    "\\end{align}\n",
    "\n",
    "Recall about matrix differentiation:\n",
    "\n",
    "\\begin{align}\n",
    "d(\\boldsymbol{A}) & = 0  \\quad \\quad \\quad \\text{if } \\boldsymbol{A} \\text{ is not function of } \\boldsymbol{X} \\\\\n",
    "d(a\\boldsymbol{X}) & = a d \\boldsymbol{X}  \\quad \\quad \\text{if } a \\text{ is not function of } \\boldsymbol{X} \\\\\n",
    "d(\\boldsymbol{X} +\\boldsymbol{Y}) & = d \\boldsymbol{X} + d \\boldsymbol{Y} \\\\\n",
    "d(\\boldsymbol{XY}) & = (d \\boldsymbol{X}) \\boldsymbol{Y} + \\boldsymbol{X} (d \\boldsymbol{Y}) \\\\\n",
    "d(\\boldsymbol{X}^T) & = (d \\boldsymbol{X})^T \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8329fe82a4ef219f244373703260931",
     "grade": true,
     "grade_id": "cell-109713b1f8185947",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "342f2ae5413de7a4e796250c94f1bc84",
     "grade": false,
     "grade_id": "cell-44cf7d2487981df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 - an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "effb405042c9f9d491937bacf136cabb",
     "grade": false,
     "grade_id": "cell-e61f02986c51754a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4399fc8c3d194a7686339617207f74f7",
     "grade": false,
     "grade_id": "cell-3f0edd2c6f447980",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the previous equations to compute **by hand** (*i.e.* in the cell below or on a sheet of paper that you paste below - New Cell > Markdown > Edit > Insert Image) the optimal parameters $\\theta_0$ and $\\theta_1$ of the model $y = \\theta_0 + \\theta_1 x$ to best fit the following dataset (of four observations):\n",
    "\n",
    "$$\\mathcal{D} = \\left\\{\n",
    "\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\n",
    "\\begin{pmatrix} 4 \\\\ 2 \\end{pmatrix},\n",
    "\\begin{pmatrix} 8 \\\\ 3 \\end{pmatrix},\n",
    "\\begin{pmatrix} 15 \\\\ 4 \\end{pmatrix}\n",
    "\\right\\}$$\n",
    "\n",
    "This will require [inverting a 2x2 matrix](https://www.chilimath.com/lessons/advanced-algebra/inverse-of-a-2x2-matrix/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e9588a241f503536ebb323c622a27b0",
     "grade": false,
     "grade_id": "cell-5ecddff6120fad94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall that for a 2x2 matrix the inverse is:\n",
    "\n",
    "$\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}^{-1} = \\frac{1}{ad-bc} \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1486af52bcc815854c8d05ed52aa62b7",
     "grade": false,
     "grade_id": "cell-dc059da0f663bf52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [1, 4, 8, 15]\n",
    "y = [1, 2, 3, 4]\n",
    "\n",
    "plot_XY(X, y);  # see in above how this is plotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3dcc4030dc11bbff95b15a4cd50489ec",
     "grade": true,
     "grade_id": "cell-9b331f739a212645",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "80e38b871ed608cd04c6ebd288fc2593",
     "grade": false,
     "grade_id": "cell-9ab9b404e1d089d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e4be157f258552500dae33861615bf6",
     "grade": false,
     "grade_id": "cell-16b61b67d4d42e31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check graphically that the model you obtained fits the data well using the following cell (uncomment and complete the first two lines and uncomment the last one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12d260fab3bf598a41c6a6e838639571",
     "grade": false,
     "grade_id": "cell-165c879595db8236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_q2(X: np.array, y: np.array, theta_0: float = None, theta_1: float = None):\n",
    "    \"\"\"\n",
    "    Puts X and y in a dataframe and plot the result; expects one-dimensional inputs X and y.\n",
    "    If theta_0 and theta_1 are provided, calculate and plot y_hat as well.\n",
    "\n",
    "    :param numpy.array X: one-dimensional regression feature\n",
    "    :param numpy.array y: one-dimensional target feature\n",
    "    :param float theta_0: constant linear regression coefficient\n",
    "    :param float theta_1: linear regression coefficient associated with X\n",
    "    \"\"\"\n",
    "    ax = plot_XY(X, y)\n",
    "\n",
    "    if theta_0 is not None and theta_1 is not None:\n",
    "        x = np.array([1, 15])\n",
    "        y = theta_0 + theta_1 * x\n",
    "        ax.plot(x, y, \"--r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1caa137ebf9559c88319912c7f1db34c",
     "grade": false,
     "grade_id": "cell-504e60e2735f1d5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT ROUND OFF THE PREVIOUSLY CALCULATED VALUES\n",
    "# theta_0 = ...  # <- TO UNCOMMENT AND TO COMPLETE (intercept)\n",
    "# theta_1 = ...  # <- TO UNCOMMENT AND TO COMPLETE (slope)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plot_q2(X, y, theta_0, theta_1)  # see above how this is plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5539f3a2acd1f5d3621f5364df7419de",
     "grade": true,
     "grade_id": "cell-e6276dfa3ea06270",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert theta_0 == 57. / 55."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c414fb572355554168d02025e1ae5796",
     "grade": false,
     "grade_id": "cell-6b304de18ae86fa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b966bb1afe8ae0314cbe3625b173fc79",
     "grade": false,
     "grade_id": "cell-b989380b0c14d3fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the MSE $E(\\boldsymbol{\\theta})$ with the following cells.\n",
    "What is plotted? What is the input space and the output space?\n",
    "\n",
    "What can you say about these plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ba46b6d1d3b22524b21632eac6a556",
     "grade": false,
     "grade_id": "cell-ffc9930c3f3c6455",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's put X, y (lists) in arrays\n",
    "X = np.array([[1, 1, 1, 1], X]).T\n",
    "y = np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b281174797346638ba2dffcf7db8f899",
     "grade": false,
     "grade_id": "cell-618afa9e58ef48b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10736e87548eea21813705b1c14dcb19",
     "grade": false,
     "grade_id": "cell-53d8fd0d6c0c2eff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd059ce39c0dd2615428e9ea9de0807",
     "grade": false,
     "grade_id": "cell-e2d36bffce65e8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_contour_2d_solution_space(\n",
    "    func, fig=None, ax=None, theta_min: np.array = None, theta_max: np.array = None,\n",
    "    theta_star: np.array = None, theta_visited: np.array = None, title: str = \"\"):\n",
    "    \"\"\"\n",
    "    Plot points visited during the execution of an optimization algorithm.\n",
    "    \"\"\"\n",
    "    if (fig is None) or (ax is None):\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Define limits of the plot\n",
    "    if theta_visited is not None:\n",
    "        if theta_min is None or theta_max is None:\n",
    "            theta_min = np.min(theta_visited, axis=0) - 2\n",
    "            theta_max = np.max(theta_visited, axis=0) + 2\n",
    "        if theta_star is not None:\n",
    "            theta_min = np.minimum(theta_min, theta_star.T)[0] - 2\n",
    "            theta_max = np.maximum(theta_max, theta_star.T)[0] + 2\n",
    "\n",
    "        theta_min = np.amin(np.hstack([theta_min.reshape([-1, 1]), theta_visited.T]), axis=1)\n",
    "        theta_max = np.amax(np.hstack([theta_max.reshape([-1, 1]), theta_visited.T]), axis=1)\n",
    "\n",
    "    x1_space = np.linspace(theta_min[0], theta_max[0], 200)\n",
    "    x2_space = np.linspace(theta_min[1], theta_max[1], 200)\n",
    "    x1_mesh, x2_mesh = np.meshgrid(x1_space, x2_space)\n",
    "    zz = func(np.array([x1_mesh.ravel(), x2_mesh.ravel()])).reshape(x1_mesh.shape)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    # Define points of minimum and maximum of func within these limits\n",
    "    if theta_star is not None:\n",
    "        min_value = func(theta_star)\n",
    "    else:\n",
    "        min_value = zz.min()\n",
    "        \n",
    "    max_value = zz.max()\n",
    "    levels = np.logspace(0.1, 3., 5)\n",
    "    # Plot area and output color given value of func\n",
    "    im = ax.pcolormesh(x1_mesh,\n",
    "                       x2_mesh,\n",
    "                       zz,\n",
    "                       vmin=min_value,\n",
    "                       vmax=max_value,\n",
    "                       shading='gouraud',\n",
    "                       cmap='gnuplot2')\n",
    "\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "    cs = plt.contour(x1_mesh,\n",
    "                     x2_mesh,\n",
    "                     zz,\n",
    "                     levels,\n",
    "                     linewidths=(2, 2, 2, 2, 3),\n",
    "                     linestyles=('dotted', '-.', 'dashed', 'solid', 'solid'),\n",
    "                     alpha=0.5,\n",
    "                     colors='white')\n",
    "    ax.clabel(cs, inline=False, fontsize=12)\n",
    "\n",
    "    ############################\n",
    "\n",
    "    # Add visited theta to the plot during gradient descent\n",
    "    if theta_visited is not None:\n",
    "        ax.plot(theta_visited.T[0],\n",
    "                theta_visited.T[1],\n",
    "                '-og',\n",
    "                alpha=0.5,\n",
    "                label=\"$visited$\")\n",
    "\n",
    "    ############################\n",
    "\n",
    "    # Add theta_star as a point to the plot. N.B.: it should lie at the minimum of func!\n",
    "    if theta_star is not None:\n",
    "        sc = ax.scatter(theta_star[0],\n",
    "                        theta_star[1],\n",
    "                        c='red',\n",
    "                        label=r\"$\\theta^*$\")\n",
    "        sc.set_zorder(10)  # put this point above every thing else\n",
    "\n",
    "    ############################\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(r\"$\\theta_0$\", fontsize=16)\n",
    "    ax.set_ylabel(r\"$\\theta_1$\", fontsize=16)\n",
    "    ax.legend(fontsize=16)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b79b9af588f9220a81494d031b0d4392",
     "grade": false,
     "grade_id": "cell-6a8128493dfd49c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MSE:\n",
    "    \"\"\"This class computes mean-squared-error of E(theta) given initial X, y.\"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"Use always the same X, y. N.B.: __init__ is the method called when instanciating a new object of this class.\"\"\"\n",
    "        self.X = np.copy(X)\n",
    "        self.y = np.copy(y)\n",
    "        \n",
    "    def __call__(self, theta):\n",
    "        \"\"\"Compute E(\\theta). N.B.: __call__ is the method called when using parentheses () on an existing object of this class,\n",
    "        i.e. acts as a function call.\"\"\"\n",
    "        return ((np.tile(self.y, theta.shape[1]) - np.dot(self.X, theta))**2).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cf6998f7c61598590afef7bd073d2fd",
     "grade": false,
     "grade_id": "cell-34f8133bfe32c617",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mse = MSE(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9f0e56be02575f846be5afbf9b1b33d",
     "grade": false,
     "grade_id": "cell-7b5a60ff721eeab2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# see above how this is plotted\n",
    "plot_contour_2d_solution_space(func=mse,\n",
    "                               theta_min=np.array([-5, -1]),\n",
    "                               theta_max=np.array([5, 1]),\n",
    "                               theta_star=np.array([[theta_0], [theta_1]]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1b4c83c0186f7a0a8f19ffd5ad62c0e",
     "grade": false,
     "grade_id": "cell-9bc1b87aa8ef194a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "N.B.: a global qualitative answer is expected in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "133319769550773cef965643c74101ab",
     "grade": true,
     "grade_id": "cell-1bea2faf56cbc3f4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "306052048a0c1ffd67cd540dcdf4decc",
     "grade": false,
     "grade_id": "cell-66e963a155d6cda0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear regression: an approximated solution using a *gradient descent* method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b23912abc45b29811d6bb818315f856c",
     "grade": false,
     "grade_id": "cell-05d4a04f2d442539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When $(X^TX)^{-1}$ cannot be easily computed (e.g. no analytical solution or $\\mathcal{D}$ contains a lot of examples or the dimension of the solution space $\\mathcal{X}$ is too large), an approximated solution can be computed using a *gradient descent method*.\n",
    "\n",
    "Also, we'll use *gradient descent* for other models than linear regression, so this will serve as an introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2706354fc4ea45b89e2bc0ab287438f3",
     "grade": false,
     "grade_id": "cell-5efce5b0664fc655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "$\\nabla_{\\boldsymbol{\\theta}}E(\\hat{\\boldsymbol{\\theta}})$ gives the direction of the largest slope at the point $\\hat{\\theta}$.\n",
    "Thus, if we explore iteratively the parameter space by following the opposite direction of this gradient as described in the following definition, we should converge to the parameter $\\boldsymbol{\\theta}^\\star$ that minimizes the MSE, i.e. the parameter $\\boldsymbol{\\theta}^\\star$ such that $\\nabla_{\\boldsymbol{\\theta}^\\star}E({\\boldsymbol{\\theta}^\\star}) = 0$.\n",
    "\n",
    "Starting from a random point $\\boldsymbol{\\theta}$, the gradient descent method proposes a new point \n",
    "$\\boldsymbol{\\theta} \\leftarrow \\boldsymbol{\\theta} - \\eta \\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})$ at each iteration until a stopping criterion has been reached: e.g. $||\\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})||_2^2 < \\epsilon$ with $\\epsilon$ a chosen minimal length for the gradient to continue iterations.\n",
    "\n",
    "The *learning rate* $\\eta \\in \\mathbb{R}_+^*$ is a parameter to tweak for the considered problem.\n",
    "- If $\\eta$ is too large, the optimization may not converge toward 0.\n",
    "- If $\\eta$ is too small, the optimization may require a lot of iterations to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b0b8d84fd06378679e16baeda68bb37",
     "grade": false,
     "grade_id": "cell-e1e52ff12c64030a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dd09aba7390ca4243c283a2601b49ca",
     "grade": false,
     "grade_id": "cell-b6cdd776c2d8dfcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "120f4061f40699084379fe6f9e18d656",
     "grade": false,
     "grade_id": "cell-b9fe747665cacd18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall our 4 points in one-dimension, which were our earlier dataset example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7975258065c7a267053b8ad5169fab8b",
     "grade": false,
     "grade_id": "cell-a07475eeb73dccd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0929a1a81aa7c1703f7c72057d3c135",
     "grade": false,
     "grade_id": "cell-ae00df8491a32a21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea3f8a340b1db19a2691adcfe8249486",
     "grade": false,
     "grade_id": "cell-dc17898bc40ce428",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Calculate by hand (in the cell below or on a sheet of paper that you can insert as image (New Cell > Markdown > Edit > Insert Image)) the expression of the gradient $\\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta}) = \\begin{pmatrix} \\nabla_{\\boldsymbol{\\theta}_0}E(\\boldsymbol{\\theta}) \\\\ \\nabla_{\\boldsymbol{\\theta}_1}E(\\boldsymbol{\\theta}) \\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84b70360a1d37943399c2958e8252fac",
     "grade": true,
     "grade_id": "cell-07604ff10943e768",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41fb172eeeaf08130f6bede6800e85d1",
     "grade": false,
     "grade_id": "cell-4db450174a002b3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a gradient descent method to solve exercise 2 with an approximated solution.\n",
    "Use the analytic formulation of $\\nabla_{\\boldsymbol{\\theta}}E(\\boldsymbol{\\theta})$ that has been computed in exercise 1.\n",
    "\n",
    "You can use a very basic stopping criterion: the number of iterations (e.g. 10000).\n",
    "You can start with $\\eta = 0.001$.\n",
    "See default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fdfbac41692ab5d020cb49bf40f7034",
     "grade": false,
     "grade_id": "cell-afe0bcd08689954e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X: np.array, y: np.array, eta: float = 0.001, max_iteration: int = 10000, \n",
    "                     theta: np.array = np.random.normal(loc=0, scale=10, size=[2, 1])):\n",
    "    \"\"\"\n",
    "    Perform linear regression by gradient descent\n",
    "\n",
    "    :param numpy.array X: features (which should include a column of 1 if an intercept is to be fitted) - 2D\n",
    "    :param numpy.array y: targets - 2D (but shape[1] is 1! A single column!)\n",
    "    :param float eta: learning rate (the higher the faster the convergence but beware...)\n",
    "    :param int max_iteration: stop whenever this number of parameter updates has been reached\n",
    "    :param numpy.array theta: initial value of theta (could be 0 in linear regression, but in neural networks - seen later\n",
    "                              on in this course, it's better to have some random initialization)\n",
    "    :return: (grad_list, theta_list) where:\n",
    "                * grad_list is a list of length max_iteration; an entry grad_list[i] is a flat list\n",
    "                    containing delta_{\\theta_j} E(\\theta) for 0 <= j <= p\n",
    "                * theta_list is a list of length max_iteration; an entry theta_list[i] is a flat_list\n",
    "                    containing \\theta_{j} for 0 <= j <= p at iteration i\n",
    "    :rtype: (list, list)\n",
    "    \"\"\"\n",
    "    # Perform useful matrix multiplication\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    grad_list = []      # Keep the gradient of all iterations\n",
    "    theta_list = []     # Keep the solution of all iterations\n",
    "\n",
    "    for _ in range(max_iteration):\n",
    "        # Perform the gradient descent here\n",
    "        # grad = ...\n",
    "        # theta = ...\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        grad_list.append([grad[0][0], grad[1][0]])      # Keep the gradient\n",
    "        theta_list.append([theta[0][0], theta[1][0]])   # Keep the solution\n",
    "\n",
    "    return grad_list, theta_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0045927ccc31702e5589649d7e5dc15a",
     "grade": true,
     "grade_id": "cell-c2d72b650eb9188e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae90a9551dfbfe39b131539d8dd396f9",
     "grade": false,
     "grade_id": "cell-ea7a3ebf2e90c097",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "grad_list, theta_list = gradient_descent(X, y)\n",
    "\n",
    "dataframe_grad = pd.DataFrame(grad_list, columns=[\"grad1\", \"grad2\"])\n",
    "dataframe_theta = pd.DataFrame(theta_list, columns=[\"theta1\", \"theta2\"])\n",
    "\n",
    "dataframe_theta.tail()  # Display the last lines and observe convergence to what you found analytically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9029b7f56952bdb7049ab3b8d19dc31",
     "grade": false,
     "grade_id": "cell-fa5f032a678d1191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fee1e1a7073c5b8be9e2cb47054e299e",
     "grade": false,
     "grade_id": "cell-9e10cb411219f8f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the value of $\\theta$ and $E(\\theta)$ (w.r.t. $\\theta$) obtained at each iteration.\n",
    "Check that $E(\\theta)$ converges to 0 and that $\\theta$ converges to the solution obtained in exercise 2.\n",
    "\n",
    "*Hint 1*: You can use `plot_contour_2d_solution_space`, used previously.\n",
    "\n",
    "*Hint 2*: You need to pass correct arguments to `theta_visited`: the parameters that were actually obtained during gradient descent. `dataframe_theta` might come handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "109a676c7380664e103931cfb7cb5320",
     "grade": false,
     "grade_id": "cell-95c473ba9cbf5611",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# theta_visited = ...  # numpy array of values of theta obtained through gradient descent (be careful about the expected shape)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# see above how this is plotted\n",
    "plot_contour_2d_solution_space(mse,\n",
    "                               theta_visited=theta_visited,\n",
    "                               theta_star=np.array([[theta_0], [theta_1]]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14caca822d14eae0b90a05aa9dd977b8",
     "grade": false,
     "grade_id": "cell-9463cd2580ad5929",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "470fb6827d8a25483c646743f41f5ce3",
     "grade": false,
     "grade_id": "cell-e7cb91b538975eee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the norm of the gradient.\n",
    "\n",
    "*Hint*: You simply have to compute its norm in the following function.\n",
    "\n",
    "To test your work, you can make use of `dataframe_grad` provided earlier (see subsequent cell). How do you interpret it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10c76104705a75bfc2dec5ff339238b9",
     "grade": false,
     "grade_id": "cell-6c3628c367ef09e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_gradient(df_gradient: pd.DataFrame):\n",
    "    df = df_gradient.copy()  # make an alias\n",
    "    # Put the norm of the gradient at each iteration in a column named \"norm\"\n",
    "    # df['norm'] = ...\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    ax = df.norm.plot(loglog=True, figsize=(16, 8))\n",
    "\n",
    "    ax.set_title(r\"Evolution of $||\\nabla_{\\theta} E(\\theta)||_2$\", fontsize=16)\n",
    "    ax.set_xlabel(\"Iteration number\", fontsize=16)\n",
    "    ax.set_ylabel(r\"Norm of $\\nabla_{\\theta} E(\\theta)$\", fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6459da151405bbc7a09af746b05694ec",
     "grade": true,
     "grade_id": "cell-99c2cc0144478abd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_gradient(dataframe_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c9fde05d0e63c7c120b90fa07e5e50b",
     "grade": false,
     "grade_id": "cell-0c9ff61378716aa0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2152066e9b2d04d09ad17a8b06fcb95e",
     "grade": false,
     "grade_id": "cell-3d83db1d4a842a37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's wrap up to the three first questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af4894f3b704ad5d923797d4e61e7df",
     "grade": true,
     "grade_id": "cell-bbf38ec3627452f2",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Try with different values of eta (and optionally theta) IN SEPARATE CODE CELLS\n",
    "def display_theta_visited_norm(eta=0.000001, theta=np.array([[7],[2]]), max_iteration=10000):\n",
    "    ## Call your solution to Question 1 here to perform gradient descent.\n",
    "    # grad_list, theta_list = gradient_descent(...)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Use the same procedure as previously:\n",
    "    df_grad = pd.DataFrame(grad_list, columns=[\"grad1\", \"grad2\"])\n",
    "    df_theta = pd.DataFrame(theta_list, columns=[\"theta1\", \"theta2\"])\n",
    "\n",
    "    ## Use your solution to Question 2 here\n",
    "    # theta_visited = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # see above how this is plotted\n",
    "    plot_contour_2d_solution_space(mse,\n",
    "                                   theta_visited=theta_visited,\n",
    "                                   theta_star=np.array([[theta_0], [theta_1]]))\n",
    "    plt.show()\n",
    "    ## Use your solution to Question 3 here (nothing to do, everything is already implemented in plot_gradient)\n",
    "    # Computing the norm\n",
    "    plot_gradient(df_grad)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fdcb422933d157398cb96fd0fc26a06",
     "grade": false,
     "grade_id": "cell-b6f73284671c964c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's restart the optimization using a different *learning rate* $\\eta$.\n",
    "\n",
    "What do you observe for a small $\\eta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d676f26d792f7833eebf929f7266ae1b",
     "grade": true,
     "grade_id": "cell-137404677de06a04",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d69ff1b864a86b48011559cdfd3dfd9",
     "grade": true,
     "grade_id": "cell-b2d33e0b58aa0a50",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "276fa201e91760a4a6c884259d0d0e6f",
     "grade": false,
     "grade_id": "cell-32f2e872f774493e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What do you observe for a large $\\eta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d5791c09ba6423f5108be7af353fbda",
     "grade": true,
     "grade_id": "cell-f36a940ff6361975",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3dffb0f1c5479401e41a16c7a2087b3",
     "grade": false,
     "grade_id": "cell-faddd7708455b944",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In-between (too small and too large value for $\\eta$), you should find some value where something \"strange\" happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "116d9d30c495d4a9c4e4aecbf6628bc0",
     "grade": true,
     "grade_id": "cell-f0756f5088f332b9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# display_theta_visited_norm(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11d22a47c001cf1503286332a9f2bb36",
     "grade": true,
     "grade_id": "cell-f1342ed3d5337e67",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4655427807a7168080483689671039ae",
     "grade": true,
     "grade_id": "cell-24168347033f89a0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1a396a08bb793c451f8fd06ef8ef73f",
     "grade": false,
     "grade_id": "cell-a7594039d1965484",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear regression with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3acee9ab14cb933a8b92c68b96894d2b",
     "grade": false,
     "grade_id": "cell-80cf226d39c1feeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's play with the Scikit Learn implementation of linear regression.\n",
    "The official documentation is there: https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65892b9660715da48adcdf7f23f5d2c5",
     "grade": false,
     "grade_id": "cell-b160f4cf12cf6b6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `gen_1d_linear_regression_samples()` function (defined above) to generate a dataset and `plot_1d_regression_samples()` to plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b78153f5a5c2f091396b76b23d1f7a",
     "grade": false,
     "grade_id": "cell-0bda972706db0f96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_1d_linear_regression_samples()\n",
    "\n",
    "plot_1d_regression_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43818da8ae6818cf5bc9c139a5eb4e5e",
     "grade": false,
     "grade_id": "cell-932ebeb64bb5a2b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once the dataset is ready, let's make the regressor and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a818931c5de409cb3ceb9b5c777629b",
     "grade": false,
     "grade_id": "cell-f09fbaa43b826133",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "linear_model.fit(df[['x']], df[['y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50532f9bf585d19902058fdd9dc429fb",
     "grade": false,
     "grade_id": "cell-5e8fe8ffeef9eba2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is equivalent to your function `gradient descent`. The `linear_model` object contains, among others, the final parameters (similar to `theta_list[-1]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c894ac1abd8daf1075d9da7d865c5d7",
     "grade": false,
     "grade_id": "cell-39264ad22cf7a195",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell plots the learned model (the red dashed line) and the dataset $\\mathcal{D}$ (blue points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2017b717bde735a23620c21d0eae6f6d",
     "grade": false,
     "grade_id": "cell-edc6674474d43365",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_1d_regression_samples(df, model=linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "477ee209454a9d608db067ab6f91a9aa",
     "grade": false,
     "grade_id": "cell-b7fbd3a64e51ee80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54d622ae9f519485318c1ee2e1823edd",
     "grade": false,
     "grade_id": "cell-1770c0dbfa328904",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5bfe680392c957cf006c23288e2679cd",
     "grade": false,
     "grade_id": "cell-0c8e89bc5e840013",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are the optimal parameters $\\theta_0$ (intercept) and $\\theta_1$ obtained? Put them in `intercept` and `slope` **as floats**.\n",
    "(Note: there are attributes to the `LinearRegression` class which provide them - you should probably check the documentation linked above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a300a756fda14a2d125deffde981183",
     "grade": false,
     "grade_id": "cell-e2aa27ffe5b33569",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# intercept = ...  # TO UNCOMMENT\n",
    "# slope = ...  # TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"Model intercept:\", intercept)\n",
    "print(\"Model slope:    \", slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffaab9f7c3d0d5b9023d03c6feebc14c",
     "grade": true,
     "grade_id": "cell-a310e1610f39308d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8376a041786b81cfe60ddfd904f4cc22",
     "grade": false,
     "grade_id": "cell-7f425446c98adcae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fb4ca06948268030f48532317d35127",
     "grade": false,
     "grade_id": "cell-3af6a3541617d567",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write the mathematical definition of the oracle (the data generating mechanism, see above) and your model.\n",
    "\n",
    "Implement both as a function of X and plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f51b002732149297bfca8997a5c7dbd",
     "grade": true,
     "grade_id": "cell-2bd7bc7d944edb1b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12a15cc51a9412963e9d963bb3581b49",
     "grade": true,
     "grade_id": "cell-5eb0efb6698f74f5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def f_hat(X):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y', figsize=(16, 6))\n",
    "\n",
    "X = np.array([-10, 10])\n",
    "ax.plot(X, f(X))\n",
    "ax.plot(X, f_hat(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b92952d375f5bc4d985d63640757803",
     "grade": false,
     "grade_id": "cell-a7c01692a2600a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3068d952923b06f88e6bb0b69eba5864",
     "grade": false,
     "grade_id": "cell-61e1f78258673ea2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `model.predict()` function to guess the class of the following points in a *vectorized* way (i.e. applying the `predict` method on an array, and returning and an array); put the result in `linear_predictions`:\n",
    "\n",
    "$$x_{p1} = -2, \\quad x_{p2} = 2, \\quad x_{p3} = 6$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5419d9947e52f5f9d5e9532c039d9fc7",
     "grade": false,
     "grade_id": "cell-3b0196a9e393373d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predictions = ...  # TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6defb98e773cac6fedbfdcf045ccb1c9",
     "grade": true,
     "grade_id": "cell-b08dd318b2a33497",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e315b43b89e7b504d7eb8ffe7f64b03c",
     "grade": false,
     "grade_id": "cell-ea69acf8a4eeafae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c6b2f359ab76b7f67397163f2fd9851",
     "grade": false,
     "grade_id": "cell-9af4759b11aae65e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It is a common practice to use linear models trained on nonlinear transformations of the input data in machine learning. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.\n",
    "\n",
    "For instance, a linear model can be extended by making polynomial features from the coefficients. Linear model in exercises 1 and 2 looks like this (one-dimensional data):\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 x$$\n",
    "\n",
    "If we want to fit a quadratic curve to the data instead of a line, we can combine the features in second-order polynomials, so that the model looks like this:\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 x + \\theta_2 x^2$$\n",
    "\n",
    "This is still a linear model: to illustrate this, we can create a new variable\n",
    "\n",
    "$$z = [x, x^2]$$\n",
    "\n",
    "With this re-labeling of the data, our problem can be written\n",
    "\n",
    "$$f_{\\theta}(x) = \\theta_0 + \\theta_1 z_1 + \\theta_2 z_2$$\n",
    "\n",
    "The resulting polynomial regression is in the same class of linear models we'd considered above (i.e. the model is linear in $\\theta$) and can be solved by the same techniques. Thus the linear model has the flexibility to fit a much broader range of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99e1d0a1f7658bf7acae763e31380328",
     "grade": false,
     "grade_id": "cell-da455a84c874bc2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf84ed078b65a089bbaa54517ba3d90d",
     "grade": false,
     "grade_id": "cell-c5abc9da3393b15e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5188dcdba176ffbc931c5b5c4c5b4e76",
     "grade": false,
     "grade_id": "cell-b2b7efb8efee00d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the previous equations to compute **by hand** (i.e. on a sheet of paper) the optimal parameters $\\theta_1$ and $\\theta_2$ of the model $y = \\theta_1 x + \\theta_1 x^2$ to best fit the following dataset (of four examples):\n",
    "\n",
    "$$\\mathcal{D} = \\left\\{\n",
    "\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\n",
    "\\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix},\n",
    "\\begin{pmatrix} 3 \\\\ 3 \\end{pmatrix},\n",
    "\\begin{pmatrix} 4 \\\\ 3.5 \\end{pmatrix},\n",
    "\\begin{pmatrix} 5 \\\\ 3.7 \\end{pmatrix}\n",
    "\\right\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0469afbe4f1ad11ac37d01865b37121e",
     "grade": true,
     "grade_id": "cell-9a82b72415381982",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cf32152d3f02ef4169c3641e05e4ab9",
     "grade": false,
     "grade_id": "cell-67f540250ea72831",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can (optionnally) check your results using `numpy`. See e.g. `@`, `np.dot`, `np.matmul` and `np.linalg.inv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b79121946de84536f0dadc9f4d6080c",
     "grade": false,
     "grade_id": "cell-2c1a044c8c32910c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad78bd258da907040c810480cc3ef67d",
     "grade": false,
     "grade_id": "cell-9a0d8e56ddad1916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's plot these points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276f7451d8509a79bde8469d1acb6431",
     "grade": false,
     "grade_id": "cell-88fcd160737086f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "y = [0, 2, 3, 3.5, 3.7]\n",
    "\n",
    "plot_ex4(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d32efa1d94823864b71d82677a14eaa",
     "grade": false,
     "grade_id": "cell-5dc7678377669961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a4b97feb1a79cab8969b92f2714067d",
     "grade": false,
     "grade_id": "cell-c8925b27745ffbe3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Check graphically that the model you obtained fits the data well using the following cell (complete the first two lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f20bd053dd9d96090db608c47eae6a5",
     "grade": false,
     "grade_id": "cell-743068a487e386fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "y = [0, 2, 3, 3.5, 3.7]\n",
    "\n",
    "# theta_1 = ...  # <- TO UNCOMMENT\n",
    "# theta_2 = ...  # <- TO UNCOMMENT\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plot_ex4(X, y, theta_1, theta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fca3967c03c86d90f38fc46ae17523b6",
     "grade": true,
     "grade_id": "cell-68076cc461b7aa4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8f43ce5e4a2afa74261e6ef52f952ce",
     "grade": false,
     "grade_id": "cell-889afbb56bb539bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This doesn't seem very good: why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b773c5a40edb81ee87bd1a88e53bce54",
     "grade": true,
     "grade_id": "cell-e122f22ad443e026",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dd05aa7b30f9ae6a5b8579b0f7e36fa",
     "grade": false,
     "grade_id": "cell-0fe2836d24ce791b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial regression with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "406336b103c4a1c0f4acb7e550d1e3d8",
     "grade": false,
     "grade_id": "cell-273e499ff0c0af37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's play with the Scikit Learn implementation of polynomial regression.\n",
    "The official documentation is there: https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a26a20b2e1239aba3e018d63b039b1",
     "grade": false,
     "grade_id": "cell-b18c3e59c8b19397",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we generate the dataset (see `gen_1d_polynomial_regression_samples` defined above), plot it, instantiate a regressor and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "337ec8d6c8a67a7867b638336167aa6c",
     "grade": false,
     "grade_id": "cell-4b9b035c8e1beb91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_1d_polynomial_regression_samples(n_samples=200)\n",
    "plot_1d_regression_samples(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b7fa61b3627dcd293b8ef0abe1b1462",
     "grade": false,
     "grade_id": "cell-ad8985a383fad72d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "polynomial_features = sklearn.preprocessing.PolynomialFeatures(degree=3)  # In Q. 4, try with degree = 1, 4 and 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6582bf6bc6fc1e87da047171aa2ca668",
     "grade": false,
     "grade_id": "cell-60b5a0fd85c1b670",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In `sklearn.preprocessing.PolynomialFeatures()`, `degree` is the degree of the polynomal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa0b6c66b34a4abf3c3d0900d0c0698f",
     "grade": false,
     "grade_id": "cell-cb4fbf2bd2a6ea31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def learn_poly_model(poly_features: sklearn.preprocessing.PolynomialFeatures):\n",
    "    # no intercept in the LinearRegression since PolynomialFeatures includes a \"bias\"\n",
    "    # see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\n",
    "    linear_regression = sklearn.linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "    model = sklearn.pipeline.Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                                       (\"linear_regression\", linear_regression)])\n",
    "\n",
    "    model.fit(df[['x']], df[['y']])\n",
    "    return linear_regression, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2506873238896f9f324b66bcd7a825f",
     "grade": false,
     "grade_id": "cell-ec91a7caa3fcf540",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "linear_regression, model = learn_poly_model(polynomial_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37b3f8075594e8a10ab7826c6f20d78b",
     "grade": false,
     "grade_id": "cell-1ec55b18f7da9027",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell plots the learned model (the red dashed line) and the dataset $\\mathcal{D}$ (blue points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5acdd9b522fc0d044c67920efd15d2be",
     "grade": false,
     "grade_id": "cell-a82fa33137de7f52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f999d230165ef0cbb5e8e03fb13bf15e",
     "grade": false,
     "grade_id": "cell-ca25c567cdcf63dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08b399531a3b962d669e4dba0dec2e62",
     "grade": false,
     "grade_id": "cell-df3505a40854ace0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ce408d3f025dfd9ef41d7c8b2d010e6",
     "grade": false,
     "grade_id": "cell-41f631b52fc8952d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What are the optimal parameters $\\theta_0, \\theta_1, \\theta_2, \\theta_3$ obtained (**as floats**)? Check the attributes of `linear_regression`. Remember from above that a bias term (1) is included in the PolynomialFeatures but we did not allow (which would be redundant) LinearRegression to fit an intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "206179ae1d3d5e80b626e85a07823d67",
     "grade": false,
     "grade_id": "cell-b91f19a4815fe3af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# theta_0 = ...\n",
    "# theta_1 = ...\n",
    "# theta_2 = ...\n",
    "# theta_3 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"theta_0 (intercept):\", linear_regression.coef_[0][0])\n",
    "print(\"theta_1:            \", linear_regression.coef_[0][1])\n",
    "print(\"theta_2:            \", linear_regression.coef_[0][2])\n",
    "print(\"theta_3:            \", linear_regression.coef_[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffc5b0e6ddf65349bebe05faa3f1dc25",
     "grade": true,
     "grade_id": "cell-bb52e963cc4ce55c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae94fcdfdf7e3caa9f0f00eae0ee777f",
     "grade": false,
     "grade_id": "cell-abaee08269799d13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f37a563c1c7fabf8bc621f574272074",
     "grade": false,
     "grade_id": "cell-0fa045dedd3f7af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Write the mathematical definition of the generated data (see above) and your model. Plot the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b9f9d9af619cd0ef1d74350704a1e1f",
     "grade": true,
     "grade_id": "cell-c98b8e5c3afe817b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c95c93926a8f4a87f11e6775b46c8eca",
     "grade": false,
     "grade_id": "cell-9b7da27fe4c56be2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5., 5., 50)\n",
    "\n",
    "# y_hat = ...  # <- TO UNCOMMENT: this is sklearn's prediction\n",
    "# y = ...  # <- TO UNCOMMENT: this is the equation you found by looking above\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y', figsize=(14, 6))\n",
    "\n",
    "df_model = pd.DataFrame(np.array([x, y, y_pred]).T, columns=['x', 'y', 'y_pred'])\n",
    "\n",
    "df_model.plot(x='x', y='y', style=':r', label='actual y', ax=ax)\n",
    "df_model.plot(x='x', y='y_pred', label='y predicted', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc8c29d9d09880d516b0bb130a355cf9",
     "grade": false,
     "grade_id": "cell-34a1d1428212f1d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c520fa4dc80c504b8e60c11b69224d21",
     "grade": false,
     "grade_id": "cell-92778884a8237af7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the `model.predict()` function to infer the `y` value of the following points:\n",
    "\n",
    "$$x_{p1} = 1, \\quad x_{p2} = 2, \\quad x_{p3} = 6$$\n",
    "\n",
    "Put the result in `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5eb339248aa70f8f59b31bb479f5572",
     "grade": false,
     "grade_id": "cell-5316fdd4671338b9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predictions = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d87421d5fa9bca323050c4cc8b00d1c5",
     "grade": true,
     "grade_id": "cell-9139d7805b7a5da9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3d719f7ee4cc318048bfadc85c1a938",
     "grade": false,
     "grade_id": "cell-6dfe74e982d3c4a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f009e79311993a6d7fdc7848feb9ca1",
     "grade": false,
     "grade_id": "cell-177f5049053e9bdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In `sklearn.preprocessing.PolynomialFeatures()`, change the value of `degree` and describe what happen on the plot (use e.g. 1 and 15 - possibly with fewer observations).\n",
    "What is the name of the observed phenomenons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "981054a726c3db34dc958d9f5f682302",
     "grade": true,
     "grade_id": "cell-4159c28a527f8e14",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69063699ff53a3ea0ef524c6bad54903",
     "grade": true,
     "grade_id": "cell-803b95bd0c968001",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# polynomial_features = ...  # TO UNCOMMENT, use e.g. degree 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "linear_regression, model = learn_poly_model(polynomial_features)\n",
    "\n",
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3aaf892a5919f8dbf4ba6b13d4c51e3",
     "grade": true,
     "grade_id": "cell-e840b6c03f7592a6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf8407574bd6356b1832080f12e27b02",
     "grade": true,
     "grade_id": "cell-32f3059837b84e50",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_1d_polynomial_regression_samples(n_samples=10)\n",
    "\n",
    "# polynomial_features = ...  # TO UNCOMMENT, use e.g. degree 15\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "linear_regression, model = learn_poly_model(polynomial_features)\n",
    "\n",
    "plot_1d_regression_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3186d70e3d0db76bfca5cb82c39741b",
     "grade": false,
     "grade_id": "cell-4291e83e9d6f58ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## CO2 Emission Forecast (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3422fe3ddc5916ce12105f4180b185",
     "grade": false,
     "grade_id": "cell-e2a7a58758db5540",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this exercise, you will forecast 5 years of future CO2 emission from power generation using natural gas.\n",
    "\n",
    "This exercise use a dataset taken from https://www.kaggle.com/berhag/co2-emission-forecast-with-python-seasonal-arima.\n",
    "\n",
    "This public dataset contain monthly carbon dioxide emissions from electricity generation. The dataset includes CO2 emissions starting January 1973 to July 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "843f6dac1562d2db61849c00950caaaa",
     "grade": false,
     "grade_id": "cell-f4ec940d7fe3fb22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "filepath = \"https://raw.githubusercontent.com/jeremiedecock/polytechnique-cse204-2018/master/natural_gas_co2_emissions_for_electric_power_sector.csv\"\n",
    "\n",
    "df = pd.read_csv(filepath,\n",
    "                 parse_dates=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4d406296869f74c7afb2614c36bd8b3",
     "grade": false,
     "grade_id": "cell-e569fa4bb7e02b65",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.plot(x='date', y='co2_emissions', figsize=(15,10), title='Natural Gas Electric Power Sector CO2 Emissions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4ce4345d31b108c4f0eb26fc5975a66",
     "grade": false,
     "grade_id": "cell-2524cba1576919b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 7 (bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9009024e58ef460c7140572f3a631d2b",
     "grade": false,
     "grade_id": "cell-0f3199ca4199ef09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement a model to make predictions on this dataset.\n",
    "Use polynomial basis functions plus two sinusoids to handle the seasonality of this time series: $\\sin(\\frac{2 \\pi}{12} x)$ and $\\cos\\left(\\frac{2 \\pi}{12} x \\right)$. This signal contains a periodic component of 12 time steps (**where one time step equals to one month**).\n",
    "\n",
    "We use both $\\sin$ and $\\cos$ to avoid unaligned phases with the time series. Alternatively, we could use only $\\sin\\left(\\frac{2 \\pi}{12} (x + \\phi)\\right)$ or $\\cos\\left(\\frac{2 \\pi}{12} (x + \\phi)\\right)$ as long as $\\phi$ is properly set: $\\phi = \\pi / 2$ in the first case and $\\phi = 0$ in the second one.\n",
    "\n",
    "What are the limitations of this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10b24f043ea774648ee168addf412f36",
     "grade": true,
     "grade_id": "cell-106b84e0a7ac2494",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba7f32e7ae95a8719d42da5456420395",
     "grade": true,
     "grade_id": "cell-62bb51115ccdd8a9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# X = increments by 1 for each month, see `index` or `date`\n",
    "# y = co2 emissions, see `co2_emissions`\n",
    "# Add column of 1, X², X³, ... Concatenate and create a pandas DataFrame\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "df_Z = pd.DataFrame(Z, columns=['intercept', 'z', 'z2', 'z3', 'sin', 'cos'])\n",
    "df_Z.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97c75735254061eb732ce9c524f87897",
     "grade": false,
     "grade_id": "cell-4e87cf97568b97c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With the following plot, we check that the seasonality of the time series is correctly aligned with our sine and cosine bases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af98c0a6cec1f7da808a609d0f40290b",
     "grade": false,
     "grade_id": "cell-ee0f57f8b318cc78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ax = df_Z.loc[:, ['sin', 'cos']].plot(figsize=(18,8))\n",
    "ax.plot(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d6d593ee24a1dd7dc7585a1e392d991",
     "grade": false,
     "grade_id": "cell-0006ec1dea5f87f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then we make and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a2e36419e13ba5bd254de3c29d3fbdb",
     "grade": true,
     "grade_id": "cell-a8de0d861f176e56",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model = ...\n",
    "# model.fit(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "011f8b8e6882f9009a330c85e756d158",
     "grade": false,
     "grade_id": "cell-6fd0e0c8b3f6fd4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following cell plots the learned model and the dataset $\\mathcal{D}$ (blue points):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c96fec82bc271571d5580fbd98e73b28",
     "grade": false,
     "grade_id": "cell-b97960e011f5f991",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "# Compute the model's prediction\n",
    "y_pred = model.predict(df_Z)\n",
    "ax.plot(y_pred, label=\"Precicted y\");\n",
    "\n",
    "# Plot also the training points\n",
    "ax.plot(y, label=\"Actual y\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "569667aa597933ccd66df73481331b11",
     "grade": false,
     "grade_id": "cell-e4df8a22b942b669",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then we use the model to (roughly) forecast the CO2 emission for the 5 next years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30f234e44f0ab6c2050356f5525847ec",
     "grade": true,
     "grade_id": "cell-d94f61844dd909e3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# [...]\n",
    "# df_Z_forecast = ...\n",
    "# model.predict(...)\n",
    "# ax.plot(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
