{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). On JupyterLab, you may want to hit the \"Validate\" button as well.\n",
    "\n",
    "Caution: do not mess with the notebook's metadata; do not change a pre-existing cell's type; do not copy pre-existing cells (add new ones with the + button instead). This will break autograding; you will get a 0; you are warned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%; border: none;\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
    "  <tr>\n",
    "    <td><img src=\"https://www.planetegrandesecoles.com/wp-content/uploads/2021/07/Identite%CC%81-visuelle-Plane%CC%80te-BAC-8-600x398.png\" style=\"float: left; width: 100%\" />\n",
    "</td>\n",
    "    <td><a style=\"font-size: 3em; text-align: center; vertical-align: middle;\" href=\"https://moodle.polytechnique.fr/course/view.php?id=19260\">[CSC2S004EP - 2024] - Introduction to Machine Learning</a>\n",
    "</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3697e44282b3f711ef95ef8acda0705f",
     "grade": false,
     "grade_id": "cell-016ee4458dc3052a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "meta",
     "toc_en"
    ]
   },
   "source": [
    "<a style=\"font-size: 3em;\">Lab Session 3: Logistic Regression and k-Nearest Neighbors\n",
    "</a>\n",
    "\n",
    "Jérémie DECOCK - Adrien EHRHARDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c81b2830b17651bbcf11bb5793053024",
     "grade": false,
     "grade_id": "cell-598c8d362eed3951",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "- Implement Logistic Regression and *k-Nearest Neighbor(s)*\n",
    "- Use it to solve classification (and regression) problems\n",
    "- Recognize and understand the aspects, strengths, and weaknesses of these algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "426e7917c3abf5a12b9a9967e562e5dc",
     "grade": false,
     "grade_id": "cell-08302126bd4f9851",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Imports and tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67605e7e4513248808d01eee39a01d9b",
     "grade": false,
     "grade_id": "cell-63b1b9dd8415d471",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import sklearn.neighbors\n",
    "import sklearn.linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c8404be07863f0596be38b602497dd4",
     "grade": false,
     "grade_id": "cell-a6d672836b02c093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Similar to the previous lab, we make a few helper functions to generate synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cdfde62d39cb3dc30ae5ec67b0fb9f6c",
     "grade": false,
     "grade_id": "cell-75363bce53640b3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_2d_classification_samples(n_samples: int = 20, nclass: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates 2-dimensional samples which belong to either 2 or 3 classes\n",
    "\n",
    "    :param int n_samples: number of samples to draw per class\n",
    "    :param int nclass: number of classes the samples belong to (either 2 or 3)\n",
    "    :returns: dataframe containing X (2 coordinates x1, x2) and y (as int!)\n",
    "    \"\"\"\n",
    "    cov = np.diag([1.5, 1.5])\n",
    "\n",
    "    x1 = np.random.multivariate_normal(mean=[-1., -1.], cov=cov, size=n_samples)\n",
    "    y1 = np.zeros(n_samples)\n",
    "\n",
    "    x2 = np.random.multivariate_normal(mean=[2., 0.], cov=2. * cov, size=n_samples)\n",
    "    y2 = np.ones(n_samples)\n",
    "\n",
    "    x3 = np.random.multivariate_normal(mean=[-2., 2.], cov=cov, size=3 * n_samples)\n",
    "    y3 = np.full(3 * n_samples, 2, dtype=int)\n",
    "\n",
    "    if nclass == 3:\n",
    "        X = np.concatenate([x1, x2, x3])\n",
    "        y = np.concatenate([y1, y2, y3])\n",
    "    elif nclass == 2:\n",
    "        X = np.concatenate([x1, x2])\n",
    "        y = np.concatenate([y1, y2])\n",
    "    else:\n",
    "        raise ValueError(\"Only 2 or 3 classes\")\n",
    "\n",
    "    df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "    df['y'] = y\n",
    "\n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87d1bacd70546fa7694da581100d69e8",
     "grade": false,
     "grade_id": "cell-bac96755e7e26f9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_and_plot_1d_regression_samples(n_samples : int = 40):\n",
    "    \"\"\"\n",
    "    Generates 1-dimensional regression samples\n",
    "\n",
    "    :param int n_samples: number of samples to draw\n",
    "    :returns: dataframe containing X (1 coordinate x) and y\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(low=-10., high=10., size=n_samples)\n",
    "    y = x - 2. + np.random.normal(scale=3.5, size=x.shape)\n",
    "    df = pd.DataFrame(np.array([x, y]).T, columns=['x', 'y'])\n",
    "    df.plot.scatter(x='x', y='y');\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3ff3416ffbebbc27585185ad9d7aede",
     "grade": false,
     "grade_id": "cell-9237e4a7e49f9b6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "def plot_2d_classification_samples(dataframe: pd.DataFrame, model=None,\n",
    "                                   voronoi: bool = False):\n",
    "    \"\"\"\n",
    "    Plots the 2D classification problem, possibly with the results of a given model and the Voronoi cells.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    df = dataframe  # make an alias so as not to modify dataframe\n",
    "    \n",
    "    ERROR_MSG1 = \"The `dataframe` parameter should be a Pandas DataFrame having the following columns: ['x1', 'x2', 'y']\"\n",
    "    assert df.columns.values.tolist() == ['x1', 'x2', 'y'], ERROR_MSG1\n",
    "    \n",
    "    ERROR_MSG2 = \"The `dataframe` parameter should be a Pandas DataFrame having the following labels (in column 'y'): [0, 1, 2]\"\n",
    "    labels = pd.unique(df.y).tolist()\n",
    "    labels.sort()\n",
    "    assert labels == list(range(3)) or labels == list(range(2)), ERROR_MSG2\n",
    "\n",
    "    if model is not None:\n",
    "        if voronoi:\n",
    "            # Compute the Voronoi cells            \n",
    "            vor = Voronoi(df[['x1', 'x2']])\n",
    "\n",
    "            # Plot the Voronoi diagram\n",
    "            fig = voronoi_plot_2d(vor, show_vertices=False, show_points=False);\n",
    "            fig.set_size_inches(8, 8);\n",
    "        \n",
    "        # Compute the model's decision boundaries\n",
    "        h = .02  # step size in the mesh\n",
    "        x_min, x_max = df.x1.min() - 1, df.x1.max() + 1\n",
    "        y_min, y_max = df.x2.min() - 1, df.x2.max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        \n",
    "        # Plot the model's decision boundaries\n",
    "        plt.pcolormesh(xx, yy, Z, cmap=cmap_light, alpha=0.5, shading=\"auto\")\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(df.x1, df.x2, c=df.y, cmap=cmap_bold, edgecolor='k', s=30)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=16)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8128634c7820172339bdd34175834ec7",
     "grade": false,
     "grade_id": "cell-c539d5681bd187c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression (with Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4053f2d5427c863d7f2119032695be81",
     "grade": false,
     "grade_id": "cell-f817d4a402721058",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Logistic regression is a **parametric binary classification algorithm**, so we generate a dataframe `df` containing a label `y` with only 2 classes (`0` and `1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "896198b14c4e733c9d4ee3ae22a9adad",
     "grade": false,
     "grade_id": "cell-cedbc22e4dce74e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_2d_classification_samples(n_samples = 100, nclass = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab667fd9e8cae00f021dd90d81bc861b",
     "grade": false,
     "grade_id": "cell-e3d6b53fa9768bb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_classification_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19d506f6032d9a55b0f7226873aad764",
     "grade": false,
     "grade_id": "cell-1291cbb39e9d66e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recall from last lab and lecture that to estimate a bias (also called intercept) term $\\theta_0$, we have to add a column of 1s to the design matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af0a53a922d853d7a4bd2a0e7fc777f7",
     "grade": false,
     "grade_id": "cell-f97708920edc4e00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([np.ones((df.shape[0])), df.x1, df.x2]).T\n",
    "y = np.array(df.y)\n",
    "print(\"First 10 rows/samples\")\n",
    "print(X[:10, :])\n",
    "print(\"With their respective labels\")\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a72e7e723454ded245fd0cdbf0cb9fb4",
     "grade": false,
     "grade_id": "cell-40b68107968c993d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Logistic regression is very similar to linear regression in so far as it is a **parametric model** which aims at finding a parameter $\\boldsymbol{\\theta}^\\star$ such as $f_{\\boldsymbol{\\theta}}: \\boldsymbol{x} \\mapsto y$ provides a good \"link\" between input vectors $\\boldsymbol{x} \\in \\mathbb{R}^p$ and output values $y \\in \\{0,1\\}$ in a *training set* $\\mathcal{D} = \\{(\\boldsymbol{x}^{(i)}, y^{(i)})\\}_{1 \\leq i \\leq n}$ of $n$ examples:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\theta}^\\star = \\arg\\!\\min_\\boldsymbol{\\theta} E(\\boldsymbol{\\theta}, \\mathcal{D}),\n",
    "$$\n",
    "\n",
    "where $E(\\boldsymbol{\\theta}, \\mathcal{D}) = - \\sum_{i=1}^n \\ln p_{\\boldsymbol{\\theta}}(y^{(i)} | \\boldsymbol{x}^{(i)})$.\n",
    "\n",
    "This is called the **log loss** (machine learning community), or the negative loglikelihood (statistics community).\n",
    "\n",
    "Logistic regression is a rather simple model which states:\n",
    "\n",
    "$$\n",
    "p_{\\boldsymbol{\\theta}}(1 | \\boldsymbol{x}^{(i)}) = \\frac{1}{1+\\exp{(-\\boldsymbol{\\theta}^T \\boldsymbol{x}^{(i)})}}\n",
    "$$\n",
    "\n",
    "The loss function $E(\\boldsymbol{\\theta}, \\mathcal{D})$ is convex, which means $\\boldsymbol{\\theta}^\\star$ exists, is unique, and can be obtained by minimizing $E$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9b67269597887028080c81241b2e1d9",
     "grade": false,
     "grade_id": "cell-c301c179faa98ecd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "Complete the following `gradient_descent` function implemented in the last lab to work for logistic regression. \n",
    "\n",
    "**Hint**: only the gradient needs to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4ea08a5afe77ca6625d92a49dab1f75",
     "grade": false,
     "grade_id": "cell-826e6ccd75478439",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, eta=0.001, max_iteration=10000, initial_theta=np.random.normal(loc=0, scale=10, size=[3, 1])):\n",
    "    theta = np.copy(initial_theta)\n",
    "    grad_list = []      # Keep the gradient of all iterations\n",
    "    theta_list = []     # Keep the solution of all iterations\n",
    "\n",
    "    for t in range(max_iteration):\n",
    "        # Perform the gradient descent here\n",
    "        # Warning: grad and theta are vectors but 2 dimensional (p, 1)\n",
    "        # For proper display, append 1D arrays or lists of size p to {grad,theta}list\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return grad_list, theta_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10415c77074d4b1d831ce043d11b9943",
     "grade": false,
     "grade_id": "cell-33f9a354f6a7a96d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "(You don't have to fill in anything in the following cell; it's a general comment about the solution of the previous cell which will be provided in the solutions of this lab session.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4344bfd3ef1c44df0a4996e70297597f",
     "grade": false,
     "grade_id": "cell-7533859a60567f8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a side note, we could have divided the gradient `grad` by `n` (the number of samples). It's merely some kind of convention: \n",
    "\n",
    "- If you divide by n, you have the mean-sample loss, so if you are generating data, you will converge as fast / slow (keeping eta constant) regardless of the number of samples you have, which in a way seems \"consistent\".\n",
    "\n",
    "- If you don't, you use the total loss to update the parameters, so it's also arguably \"logic\" to converge faster with a constant eta, since you have more information.\n",
    "\n",
    "For example, scikit lets you choose (normalize option): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html\n",
    "\n",
    "And by the way, for logistic regression, the \"optimal\" learning rate, which would be Newton Raphson's method (https://thelaziestprogrammer.com/sharrington/math-of-machine-learning/solving-logreg-newtons-method), is somehow also linked to the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a607d97deee5f7d82b8dec218e59b99d",
     "grade": true,
     "grade_id": "cell-00e6aaad8d91fb86",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "grad_list, theta_list = gradient_descent(X, y, eta = 0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc1def3909eebbd37ebe042a6c6ca78a",
     "grade": false,
     "grade_id": "cell-f4966497dcf9513d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You may play around back and forth with the \"learning rate\" $\\eta$ (keyword argument $\\texttt{eta}$) and display the successive values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify eta - and optionally max_iteration - and rerun graph below\n",
    "grad_list, theta_list = gradient_descent(X, y, max_iteration=10000, eta=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1e9deeece534c6e814540d7f7261971",
     "grade": false,
     "grade_id": "cell-58020eb3f120a67a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's see if it has converged by plotting the parameters w.r.t. the iteration number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89c4211db0293a16104e0a5652c30ea1",
     "grade": false,
     "grade_id": "cell-4a914191992a8326",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot([theta[0] for theta in theta_list], label=r\"$\\theta_0$\");\n",
    "plt.plot([theta[1] for theta in theta_list], label=r\"$\\theta_1$\");\n",
    "plt.plot([theta[2] for theta in theta_list], label=r\"$\\theta_2$\");\n",
    "plt.xlabel('iterations ($t$)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cee8b0d54870f1f949a2de47dcf05ffd",
     "grade": false,
     "grade_id": "cell-5e3051ce7de44c3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's see the decision boundary, i.e. the half-spaces where each label is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a64ff13ef289e024fab8f94f4be972ca",
     "grade": false,
     "grade_id": "cell-02f4f6e31a17faad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np.array((df.x1, df.x2))[0, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[0, :].max() + .5\n",
    "y_min, y_max = np.array((df.x1, df.x2))[1, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[1, :].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = 1 / (1 + np.exp(-np.dot(np.c_[np.ones((len(xx.ravel()))),\n",
    "                                  xx.ravel(), yy.ravel()], theta_list[9999])))\n",
    "plt.pcolormesh(xx, yy, (Z.reshape(xx.shape) > 0.5)*1, cmap=plt.cm.Paired)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.xlabel('$x_2$')\n",
    "plt.scatter(df.x1, df.x2, c=y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e1f27fd151ccecfb7a5c20c6217ea0f",
     "grade": false,
     "grade_id": "cell-4ec063e0844c5c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35d07f4d61000e3686b28621729a70fb",
     "grade": false,
     "grade_id": "cell-819ce233e39cb9c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "Let's do the same using scikit-learn!\n",
    "\n",
    "Similar to the previous lab, logistic regression belongs to the linear model module, and provides among others the `fit` and `predict` methods. Use the `fit` method to perform gradient descent under the hood, and then compare the coefficients obtained with scikit-learn and your gradient descent.\n",
    "\n",
    "Note that we disable the `penalty` term for now - as that is a topic we deal with next week.\n",
    "\n",
    "Note that we don't use $X$ but `df[['x1', 'x2']]`: recall from last lab that sklearn is smart enough to add the column of 1s under the hood (with the default `fit_intercept=True` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f7aff9507938a39e9f42ba4350663b8",
     "grade": false,
     "grade_id": "cell-f5bd213d69a982d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment model.fit(...) and provide the appropriate parameters)\n",
    "model = sklearn.linear_model.LogisticRegression(penalty=None)\n",
    "# model.fit(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be9a0cc7606b8a2d8c8b0f63c58ae83e",
     "grade": false,
     "grade_id": "cell-3ff39a810b648cea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's see if we came up with the same estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe89d45c011ecf6c78cf1462d70e4e5",
     "grade": false,
     "grade_id": "cell-a159ad94f5ba1a8c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Intercept\")\n",
    "print(\"=========\")\n",
    "print(\"sklearn:\\t\\t\", model.intercept_[0])\n",
    "print(\"gradient descent: \\t\", theta_list[-1][0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"theta_1\")\n",
    "print(\"=========\")\n",
    "print(\"sklearn:\\t\\t\", model.coef_[0][0])\n",
    "print(\"gradient descent:\\t\", theta_list[-1][1])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"theta_2\")\n",
    "print(\"=========\")\n",
    "print(\"sklearn:\\t\\t\", model.coef_[0][1])\n",
    "print(\"gradient descent:\\t\", theta_list[-1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40e65a09d8bcc2b4ea216b1677f9c42b",
     "grade": true,
     "grade_id": "cell-1ff57bcb5ef04db0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f1adb0802c30dec115434f631ad0dfc",
     "grade": false,
     "grade_id": "cell-5bcf88e115620105",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression with Polynomial Basis Functions\n",
    "\n",
    "We will now generate some data with a non-linear boundary between classes to illustrate the power of the logistic regression classifier with polynomial basis function features as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "427214e2d51f764d4d71cad8d257ec01",
     "grade": false,
     "grade_id": "cell-a866914d4450adac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gen_nonlinear_2d_classification_samples(n_samples: int = 20, nclass: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates 2-dimensional samples which belong to either 2 or 3 classes\n",
    "\n",
    "    :param int n_samples: number of samples to draw per class\n",
    "    :param int nclass: number of classes the samples belong to (either 2 or 3)\n",
    "    :returns: dataframe containing X (2 coordinates x1, x2) and y (as int!)\n",
    "    \"\"\"\n",
    "    cov1 = np.diag([2., 2])\n",
    "    cov2 = np.diag([6., 2])\n",
    "\n",
    "    x1 = np.random.multivariate_normal(mean=[-2., 0.], cov=cov1, size=n_samples)\n",
    "    y1 = np.zeros(n_samples)\n",
    "    x2 = np.random.multivariate_normal(mean=[1., 5], cov=cov1, size=n_samples)\n",
    "    y2 = np.zeros(n_samples)\n",
    "    x3 = np.random.multivariate_normal(mean=[2., -4.], cov=cov1, size=n_samples)\n",
    "    y3 = np.zeros(n_samples)\n",
    "\n",
    "    x4 = np.random.multivariate_normal(mean=[3., 1.], cov=cov2, size=n_samples)\n",
    "    y4 = np.ones(n_samples)\n",
    "\n",
    "    if nclass == 2:\n",
    "        X = np.concatenate([x1, x2, x3, x4])\n",
    "        y = np.concatenate([y1, y2, y3, y4])\n",
    "    else:\n",
    "        raise ValueError(\"Only 2 or 3 classes\")\n",
    "\n",
    "    df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "    df['y'] = y\n",
    "\n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eae978e4f737c66dbef2cc592f528102",
     "grade": false,
     "grade_id": "cell-3f182aa477bbca71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_nonlinear_2d_classification_samples(n_samples=100, nclass=2)\n",
    "plot_2d_classification_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b89ae173d84b701a595d863c36e8f2ce",
     "grade": false,
     "grade_id": "cell-cb3097705f6d6022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "Fit two logisic regression models.\n",
    "\n",
    "The first model called `model_lin` should be fit to the data stored in `df`, corresponding to features $x_1, x_2$ stored in `df` (yes, this is similar to what we did in Exercise 2).\n",
    "\n",
    "The second model called `model_sq` should be fit to a dataframe containing also entries corresponding to $\\boldsymbol\\phi = [x_1,x_2,x_1^2,x_2^2]^\\top$, not forgetting about the intercept term.\n",
    "\n",
    "Then, use the two models to predict the class of the center of the blue points (point (3, 1)) and store the predictions of `model_lin` and `model_sq` in `pred_lin` and `pred_sq`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "499830bcf8874659beefa4ebc55dab03",
     "grade": false,
     "grade_id": "cell-8512d0961650cb5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model_lin = sklearn.linear_model.LogisticRegression(penalty=None)\n",
    "# model_lin.fit(...)\n",
    "\n",
    "# model_sq = sklearn.linear_model.LogisticRegression(penalty=None)\n",
    "# ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "pred_lin = model_lin.predict([[3, 1]])\n",
    "pred_sq = model_sq.predict([[3, 1, 9, 1]])\n",
    "\n",
    "print(f\"Prediction of the linear model:\\t {pred_lin}\")\n",
    "print(f\"Prediction of the quadratic model:\\t {pred_sq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d465e4685aa24afada63c7c3b8602265",
     "grade": true,
     "grade_id": "cell-41cf6b695bf043b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "33aa18d6fd1a0844b630b1bc4b7101fe",
     "grade": false,
     "grade_id": "cell-746b0b2489304c2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the below code cell to visualise the decision boundaries of `model_lin` and `model_sq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80697d5c57a6313b6ba62269a29e898d",
     "grade": false,
     "grade_id": "cell-a2c2d09230477905",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# model_lin\n",
    "plt.subplot(1, 2, 1)\n",
    "x_min, x_max = np.array((df.x1, df.x2))[0, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[0, :].max() + .5\n",
    "y_min, y_max = np.array((df.x1, df.x2))[1, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[1, :].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "plt.pcolormesh(xx, yy, model_lin.predict(np.concatenate([\n",
    "    xx.ravel().reshape((-1,1)),yy.ravel().reshape((-1,1))], axis=1)).reshape(xx.shape),\n",
    "               cmap=plt.cm.Paired)\n",
    "plt.scatter(df.x1, df.x2, c=df['y']);\n",
    "\n",
    "# model_sq\n",
    "plt.subplot(1, 2, 2)\n",
    "x_min, x_max = np.array((df.x1, df.x2))[0, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[0, :].max() + .5\n",
    "y_min, y_max = np.array((df.x1, df.x2))[1, :].min() - .5,\\\n",
    "    np.array((df.x1, df.x2))[1, :].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "plt.pcolormesh(xx, yy, model_sq.predict(np.concatenate([\n",
    "    xx.ravel().reshape((-1, 1)),yy.ravel().reshape((-1, 1)),\n",
    "    xx.ravel().reshape((-1, 1))**2, yy.ravel().reshape((-1, 1))**2],\n",
    "    axis=1)).reshape(xx.shape), cmap=plt.cm.Paired)\n",
    "plt.scatter(df.x1, df.x2, c=df['y']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b71225fd8a25b5a6a88711ca32711bc6",
     "grade": false,
     "grade_id": "cell-8a207a748c7acf58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Nearest Neighbor algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0eea4c4df1271a646ee9e3262e4b6b4",
     "grade": false,
     "grade_id": "cell-ceaca5dd14cf6d38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here you will implement one of the simplest (but quite powerful) machine learning algorithm: the *Nearest Neighbor* algorithm and its extension, the *k-Nearest Neighbors* algorithm (or *kNN*). Both can be used for classification and regression tasks.\n",
    "\n",
    "Considering a dataset $\\mathcal{D}=\\{(\\boldsymbol{x}_i, y_i)_{i=1,\\dots,n}\\}$ of $n$ labeled examples, the *Nearest Neighbor* model assigns an input vector $\\boldsymbol{x}$ (of dimension $p$) to the label $y_{{\\arg\\!\\min}_{i=1,\\dots, n}d(x, x_i)}$ of its closest neighbor in $\\mathcal{D}$.\n",
    "\n",
    "The closest neighbor is defined w.r.t. a distance function $d$. This can be any metric measure, but the *Minkowski distance* (especially the classical Euclidian distance $d_2$) is the most common choice. It is defined as follows:\n",
    "\n",
    "$$d_q: \\mathbb{R}^p \\times \\mathbb{R}^p \\to \\mathbb{R}$$\n",
    "\n",
    "$$d_q(\\boldsymbol{u}, \\boldsymbol{v}) = ||\\boldsymbol{u} - \\boldsymbol{v}||_q = \\left( \\sum_{j=1}^p |u_j - v_j|^q \\right)^{1/q}$$\n",
    "\n",
    "When $q=2$, $d_q$ is the *Euclidian distance*\n",
    "\n",
    "$$d_2(\\boldsymbol{u}, \\boldsymbol{v}) = \\sqrt{\\sum_{j=1}^{p} (u_j - v_j)^2}$$\n",
    "\n",
    "When $q=1$, $d_q$ is the *Manhattan distance*\n",
    "\n",
    "$$d_1(\\boldsymbol{u}, \\boldsymbol{v}) = \\sum_{j=1}^{p} |u_j - v_j|$$\n",
    "\n",
    "When $q=\\infty$, $d_q$ is the  *Tchebychev distance*\n",
    "\n",
    "$$d_{\\infty}(\\boldsymbol{u}, \\boldsymbol{v}) = \\max_{j=1,\\dots,p} |u_j - v_j|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07710c1c3e6b190764f0a15947c4bf52",
     "grade": false,
     "grade_id": "cell-1f6f6a3951f12dc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e665b6d9d826ccbdf30a73af3dbd491",
     "grade": false,
     "grade_id": "cell-e9bcfd0ab3326493",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider this new dataset (where `volume (mL)` and `caffeine (g)` are the examples' features and where `drink` is their label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65138f72cb3ac81883e5ba96783c16d6",
     "grade": false,
     "grade_id": "cell-ba3ac476b10db9e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [[250, 0.025, 'tea'],\n",
    "        [100, 0.01,  'tea'],\n",
    "        [125, 0.05,  'coffee'],\n",
    "        [250, 0.1,   'coffee']]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['volume (mL)', 'caffeine (g)', 'drink'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd826b270e8408d92f8f2e3c680ba213",
     "grade": false,
     "grade_id": "cell-05ca02fdaa0bacb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5.1\n",
    "\n",
    "Use the Nearest Neighbor method to predict the label of a 100mL drink having 0.075g of caffeine. Store the answer as a string in the variable `answer`.\n",
    "\n",
    "N.B.: if you have some intuition about what applying kNN to this dataset would yield, just write the answer. In other words, you don't necessarily need to implement kNN to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e243ef05d2b951d7bc4de9d86d519f8",
     "grade": false,
     "grade_id": "cell-b12072a3c159f694",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer = 'None'\n",
    "# Provide some code to prove your answer.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "307064310e007fecb0e7d674bbbd06cb",
     "grade": true,
     "grade_id": "cell-090cb994bf15bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30732d0852669e8d264e4e81364727d3",
     "grade": false,
     "grade_id": "cell-c73f537f8d0b8d35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 5.2\n",
    "\n",
    "Think about: what is wrong with this prediction? How to solve this problem? (No answer expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4248ba2e4a074f3e7e625af8fb80d52",
     "grade": false,
     "grade_id": "cell-6d84fe4703f5f297",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Nearest Neighbor method with Scikit Learn\n",
    "\n",
    "Let's play with the Scikit Learn implementation of the Nearest Neighbor algorithm.\n",
    "The official documentation is here: https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab47930df07bf7a0da1bebcd5a60276e",
     "grade": false,
     "grade_id": "cell-f0252460418008ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "114e91cb84e5b31b1ddf7f89a7adade6",
     "grade": false,
     "grade_id": "cell-867ec5107fd6ffdd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We begin with a \"toy\" **classification problem**.\n",
    "\n",
    "We use the `gen_2d_classification_samples()` function (defined above) to generate a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c6bc83740653069ea7a940d0fa8b92a",
     "grade": false,
     "grade_id": "cell-d24faf84a0a70efe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_2d_classification_samples(n_samples=20)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32df2d17f702c031a727a622f75cbd4a",
     "grade": false,
     "grade_id": "cell-3ff7aee85c93c084",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here, examples are defined in $\\mathbb{R}^2$ (features are stored in columns `x1` and `x2`).\n",
    "Examples' labels are defined in the `y` column. This is similar to Exercise 1.\n",
    "\n",
    "The `y` column contains three possible labels: `1`, `2` and `3` respectively represented by the red, green and blue colors in the following figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d59679c191228ee27e60a215ed08a2a",
     "grade": false,
     "grade_id": "cell-0036ae2303f73710",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_classification_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79ea0f943e3108b6b26bdaab5963a8b3",
     "grade": false,
     "grade_id": "cell-d121d4f059178cd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Thus this toy problem is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26e4eca98c23b17fc1da4404819ef3f5",
     "grade": false,
     "grade_id": "cell-3f8711afd6b5415e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once the dataset is ready, let's make the classifier and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0c065dce0870cf74082471c34917cf9",
     "grade": false,
     "grade_id": "cell-a3ac431dac7cb135",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# 1-NN as a special case of k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d65cda28dfec21b40f9a1a05527b1b2",
     "grade": false,
     "grade_id": "cell-4a02136aa4ba916d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X=df[['x1', 'x2']].values, y=df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fecd5c4371df4b6cff8d97cd3dff346",
     "grade": false,
     "grade_id": "cell-7f48c25be7ecab35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a56e175a0f1233e43323b056625ae35",
     "grade": false,
     "grade_id": "cell-d48fdb53e319498e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6.1\n",
    "Use the `model.predict()` function to guess the class of the following points:\n",
    "\n",
    "$$x_{p1} = \\pmatrix{-2 \\\\ 0}, x_{p2} = \\pmatrix{0 \\\\ 6}, x_{p3} = \\pmatrix{8 \\\\ 0}$$\n",
    "\n",
    "Store the result in `model_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2900d8cfc3f5a5f983090a71e7fafb07",
     "grade": false,
     "grade_id": "cell-735399ef31c1c00e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model_predictions = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b239bfd8fa5c79f6fa40159f6bee4dc6",
     "grade": true,
     "grade_id": "cell-3f74ff6bfc8cdd74",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "481368eac5ddafc3053c92b130a61e51",
     "grade": false,
     "grade_id": "cell-16d51ac4f5481297",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 6.4\n",
    "The next cell generates the *Voronoï diagram* of the dataset. The Voronoï diagram makes a partition of the feature space $\\mathcal{X}$.\n",
    "Each partition is a *cell*. Think about what each cells represents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f295dbaf11031ec2980f7855f07ec2d",
     "grade": false,
     "grade_id": "cell-cf603bc2010ec3a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_classification_samples(df, model=model, voronoi=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4589c884a3891ab0a64606bbc42fdba3",
     "grade": false,
     "grade_id": "cell-e9ff08164cd1ce2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4580e0f9153e4b4f87f0ddea5c6d366d",
     "grade": false,
     "grade_id": "cell-a774cafffa6c10dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After the \"toy\" classification problem, let's work on a toy **regression problem**.\n",
    "\n",
    "The next cell generates a dataset (where 'x' is the feature and 'y' the label to predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d09c322dc2515371306ef864b166f2",
     "grade": false,
     "grade_id": "cell-85bbd276d7fc94c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_and_plot_1d_regression_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51a545a95b644b64f9ff9722b4ef191f",
     "grade": false,
     "grade_id": "cell-60f6a2ebadbdedd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Once the dataset is ready, let's make the regressor and train it with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca267b10b3a854097f675b825b316f87",
     "grade": false,
     "grade_id": "cell-287446ff89ada048",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1dcdfb4bf3efe1a8d9b4ab8e910dcabb",
     "grade": false,
     "grade_id": "cell-686a17bcfa348dca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "model.fit(df[['x']].values, df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d98a5bc2645ea3145153750472a9bbff",
     "grade": false,
     "grade_id": "cell-a117614dac4cb5b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ce8238b7d9e4ec7d757c1b28f161dcd",
     "grade": false,
     "grade_id": "cell-9dbebd964c84d52a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 7.1\n",
    "Use the `model.predict()` function to classify the following points:\n",
    "\n",
    "$$x_{p1} = \\pmatrix{-5}, x_{p2} = \\pmatrix{0}, x_{p3} = \\pmatrix{5}$$\n",
    "\n",
    "Store it in `model_predictions_bis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46f364b6ee421ef8ebfe1e6e7bd2ed9f",
     "grade": false,
     "grade_id": "cell-3720c9fe4c26a559",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# model_predictions_bis = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9c397b09a1807f5267018aed95033b3",
     "grade": true,
     "grade_id": "cell-47c3077482c5f28a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1ddf9c1244f71659e7c85de2ed1c4bd",
     "grade": false,
     "grade_id": "cell-5adbb1c7bb0d1bab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the model's decision function using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c9670ebc345282bb36bc7a175f79f07",
     "grade": false,
     "grade_id": "cell-90dd9833a9369717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_pred = np.arange(-10, 10, 0.1).reshape(-1, 1)\n",
    "y_pred = model.predict(x_pred)\n",
    "\n",
    "df_pred = pd.DataFrame(np.array([x_pred.flatten(), y_pred.flatten()]).T, columns=['x', 'y'])\n",
    "\n",
    "ax = df.plot.scatter(x='x', y='y')\n",
    "df_pred.plot(x='x', y='y', style='r--', ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e85f137c229528cdf292c4390a803347",
     "grade": false,
     "grade_id": "cell-90e628bd78839bf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 7.2\n",
    "\n",
    "Do you think this model *generalizes* well?\n",
    "\n",
    "By generalization, we mean performance on unseen - test - examples drawn from the same distribution as the seen - training - examples. Recall what happened with polynomial regression with a high degree. Why? (No answer expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6420b5c8952d59be6c6ea1aae82287a0",
     "grade": false,
     "grade_id": "cell-f2b3403a1f5d1ee9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# k-Nearest Neighbors algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a2c367da7aa6effa48f8fb99135543",
     "grade": false,
     "grade_id": "cell-42a1d3264976993b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The *Nearest Neighbor* method is very sensitive to noise: if an example in $\\mathcal{D}$ is wrongly labeled or positioned, all points in its Voronoï cell will be wrong too. The *k Neareast Neighbor* fix this weakness by considering for each prediction the label of several neighbors instead of just one.\n",
    "\n",
    "Considering a dataset $\\mathcal{D}=\\{(\\boldsymbol{x}_i, y_i)_{i=1,\\dots,n}\\}$ of $n$ labeled examples and a meta / hyper parameter $k \\in \\mathbb{N}*$, the *$k$ Nearest Neighbors* model assigns an input vector $\\boldsymbol{x}$ to the label $y$ (defined below) of its $k$ closest neighbor in $\\mathcal{D}$.\n",
    "Let's write $\\mathcal{N}_k(\\boldsymbol{x})$ the set of the $k$ nearest neighbors of $\\boldsymbol{x}$ in $\\mathcal{D}$.\n",
    "\n",
    "- For classification problems, the label assigned to $\\boldsymbol{x}$ is the **most represented label** among the nearest neighbors (majority vote)\n",
    "$$f(\\boldsymbol{x}) = {\\arg\\!\\max}_c \\sum_{i: x_i \\in \\mathcal{N}_k(\\boldsymbol{x})} \\delta(y_i, c)$$\n",
    "\n",
    "- For regression problems, the label assigned to $\\boldsymbol{x}$ is computed based on the **mean** of the labels of its nearest neighbors $\\mathcal{N}_k(\\boldsymbol{x})$\n",
    "$$f(\\boldsymbol{x}) = \\frac{1}{k} \\sum_{i: x_i \\in \\mathcal{N}_k(\\boldsymbol{x})} y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fa6f597b4eea5f4a8995a105ff28154",
     "grade": false,
     "grade_id": "cell-5eb2581cae2760bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c982e53f1899a33e0ab842c16905a73a",
     "grade": false,
     "grade_id": "cell-6545640cd5b7163f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We consider the following dataset (where `x1` and `x2` are the example features and where `y` is the example label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a18910e1fe3eb1fb8483892f33e3059",
     "grade": false,
     "grade_id": "cell-b5d26e5d9614042e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = [[1, 2, '+'],\n",
    "        [2, 1, '+'],\n",
    "        [2, 2, '-'],\n",
    "        [2, 3, '+'],\n",
    "        [1, 1, '-'],\n",
    "        [3, 3, '+']]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['x1', 'x2', 'y'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "148642484ff7ab316030fdd38c2e0bf9",
     "grade": false,
     "grade_id": "cell-75c5d4679e64a253",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 8.1\n",
    "Draw this dataset (it is OK to draw it on a sheet of paper: empty the code cell, add a Markdown cell and upload your picture by drag-and-drop; you can also make use of `df.plot`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e38ce274ed5eac114ad531a09cee078",
     "grade": false,
     "grade_id": "cell-fd27b17814e1925e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74c4b09c9dcc05acb917d84bd0c7bd1a",
     "grade": false,
     "grade_id": "cell-928724723d262d2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 8.2\n",
    "Draw the decision boundary of a Nearest Neighbor model (i.e. 1NN - also OK on a sheet of paper).\n",
    "\n",
    "You may need to convert `y` to an integer type and make good use of `KNeighborsClassifier` (see Exercise 2). See also provided helper function `plot_2d_classification_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df9801c361ad74918f2f1c36fa0aa144",
     "grade": false,
     "grade_id": "cell-0ac6789676ca7805",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Warning: if you're modifying df in place, you may need to rerun the previous cell to reload df while you debug the conversion of y\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82981fe8445f213f6d691cc0d549bc59",
     "grade": false,
     "grade_id": "cell-f88d668f7301d023",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 8.3\n",
    "Draw the decision boundary of a 3 Nearest Neighbor model (i.e. 3NN), either with code or on a sheet of paper.\n",
    "\n",
    "*Hint:* The `n_neighbors` parameter provided to the model's constructor `KNeighborsClassifier` sets the number of neighbors to consider for each prediction (i.e. `n_neighbors` this is the '$k$' of kNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fccbe39b9014e733c8c96b49f160b8d",
     "grade": false,
     "grade_id": "cell-7962f46912d3165f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e3bc4a370ea8241de7cd6fa97fdfb67",
     "grade": false,
     "grade_id": "cell-742c1de413386ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# k-Nearest Neighbor (kNN) with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7d92f8b2d50cdb4c1305ea3d2dc4220",
     "grade": false,
     "grade_id": "cell-aa5d831a4dc0138d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27d6239e9b533c0919445b0032169aa2",
     "grade": false,
     "grade_id": "cell-266a8e14dd3d2861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we regenerate the dataset used throughout Exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0153fad27babab9e7c870a7aacfd08c8",
     "grade": false,
     "grade_id": "cell-342c74d86eb54594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_2d_classification_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b29ebbb5eff1ebd4ad871c24a93aff6",
     "grade": false,
     "grade_id": "cell-a7d4a821d8322a09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_classification_samples(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8302a0abde46043b4e9a1a6faa0798d8",
     "grade": false,
     "grade_id": "cell-9c820f55c090fd94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then we instantiate the classifier, train it and plot the decision boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2d119d0c76823548f9327defd9bd59b",
     "grade": false,
     "grade_id": "cell-a14c2c93459d829b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def learn_knn_and_plot(**kwargs):\n",
    "    \"\"\"\n",
    "    Learns a knn model and plot the points, their class and the decision boundaries\n",
    "\n",
    "    :param kwargs: keyword arguments passed to KNeighborsClassifier\n",
    "    \"\"\"\n",
    "    model = sklearn.neighbors.KNeighborsClassifier(**kwargs)\n",
    "    model.fit(df[['x1', 'x2']].values, df['y'])\n",
    "    plot_2d_classification_samples(df, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0172f3627d38eed12c06fbb0077204c3",
     "grade": false,
     "grade_id": "cell-d897bede604ac50a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "learn_knn_and_plot(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29259a3f6d82d62eec3074738e2af5d0",
     "grade": false,
     "grade_id": "cell-cb6152f4d8230f10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "44e385a5ccd9135fbf8aa3a20ecec110",
     "grade": false,
     "grade_id": "cell-6b87f10bd0219699",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 9.1\n",
    "Change the value of the hyperparameter $k$ in the cell above, and observe what happens, i.e. plot the resulting boundaries with the subsequent cell.\n",
    "\n",
    "What is the influence of the number of neighbors on the boundaries? (Bonus points for the two extreme cases!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94fd6c022d9497a3500a55028930e34",
     "grade": false,
     "grade_id": "cell-83a85512470f18b1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# learn_knn_and_plot(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fef6c7dd5258e5063af6be19ae036e6a",
     "grade": false,
     "grade_id": "cell-198944484a425e52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should see that larger $k$ produce \"smoother\" boundaries. In general, a model with e.g. $k=5$ is less influenced by the noise contained in the dataset than a model with $k < 5$, i.e., it generalize better.\n",
    "\n",
    "$k=1$ is 1-NN already discussed.\n",
    "\n",
    "If $k \\geq n$ (with $n$ the number of elements in the dataset $\\mathcal{D}$) then all predicted points have the label of the most represented class (see question 4 in case of equals representations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a675335dc2cd113a9a2c77db52b7c67",
     "grade": false,
     "grade_id": "cell-1c3718c15cbacf2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the Voronoi diagram is not usefull when $k>1$. The influence of each seed now depends on $k$ and the coordinates of the others points. We cannot associate the cells' boundaries to the decision boundaries anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59e5cea687e22e4921308f8f1da7528c",
     "grade": false,
     "grade_id": "cell-250c83fcd9392137",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 9.4\n",
    "Plot the decision boundary with $k=2$ (make use of the code above) and observe what happens in case of equal vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12c098534d2743125769ca3aaf3c9a4a",
     "grade": false,
     "grade_id": "cell-89461ef88df42b1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# learn_knn_and_plot(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be648ae0b5730feaf4d555a741cae0cb",
     "grade": false,
     "grade_id": "cell-f54ae0b732531889",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 9.5\n",
    "Add the `weights = \"distance\"` parameter in `KNeighborsClassifier`'s constructor, and repeate (again, for $k=2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12a4bae323bed2a653fab8aaf3928e8a",
     "grade": false,
     "grade_id": "cell-40d043d5d08b28a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# learn_knn_and_plot(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cac3350807cb2af1779c70ab638de01b",
     "grade": false,
     "grade_id": "cell-97e9173553a38afc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With this parameter enabled, the influence of the k nearest neighbors is weighted by their proximity to the point $\\boldsymbol{x}$ to predict.\n",
    "\n",
    "It resolves ambiguities but may make models more sensitive to the noise contained in $\\mathcal{D}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff85e141a70c3ba86c80bc23b3acc10d",
     "grade": false,
     "grade_id": "cell-fe06326c2b4b6e24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1168d50095885c86cd490dc387e5509",
     "grade": false,
     "grade_id": "cell-245c508a9c8609e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we regenerate the dataset from Exercise 4 - Regression with 1-NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0881136b881af34d81ab02b272de7539",
     "grade": false,
     "grade_id": "cell-0502bea5c9bcd5fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = gen_and_plot_1d_regression_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99b7e07b31aa955ec93b6b58545e5d96",
     "grade": false,
     "grade_id": "cell-8f1da87c76b82ccc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then we instantiate the classifier, train it and plot the decision boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca165fa60380605a853e9ac1431eb29f",
     "grade": false,
     "grade_id": "cell-35d779b892b1fd52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_plot_knn_regressor(**kwargs):\n",
    "    \"\"\"\n",
    "    Instantiate, fits a KNN regressor and plots the training points as well as the predictions\n",
    "\n",
    "    :param kwargs: keyword arguments passed to KNeighborsRegressor constructor\n",
    "    \"\"\"\n",
    "    model = sklearn.neighbors.KNeighborsRegressor(**kwargs)\n",
    "    model.fit(df[['x']].values, df['y'])\n",
    "\n",
    "    x_pred = np.arange(-10, 10, 1).reshape(-1, 1)\n",
    "    y_pred = model.predict(x_pred)\n",
    "\n",
    "    df_pred = pd.DataFrame(np.array([x_pred.flatten(), y_pred.flatten()]).T, columns=['x', 'y'])\n",
    "\n",
    "    ax = df.plot.scatter(x='x', y='y')\n",
    "    df_pred.plot(x='x', y='y', style='r--', ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9afba532f651fd7490cfc4b162f4cc10",
     "grade": false,
     "grade_id": "cell-490250cefad68a4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_and_plot_knn_regressor(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07c30cbfff2405f415d07bf3ab6d5610",
     "grade": false,
     "grade_id": "cell-882dc0dc6ed1f677",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now it looks much smoother; similar to the classification example, there is a **tradeoff** between high and low value of k, a **bias-variance tradeoff** that will be the subject of the next lectures. We explore this empirically in the next exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e181e0c7f92157e77674716fc1f51a7",
     "grade": false,
     "grade_id": "cell-83b5516abfa46214",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa24e1b442c86c5e3e061c4375b09839",
     "grade": false,
     "grade_id": "cell-01a22a7f46b1071d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Recall*: The `n_neighbors` parameter provided to the model's constructor `KNeighborsClassifier` sets the number of neighbors to consider for each prediction (i.e. `n_neighbors` this is the '$k$' of kNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e880241ae0a3cc08d642659bc440a4e",
     "grade": false,
     "grade_id": "cell-3427a047b3fbf79a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 10.1\n",
    "\n",
    "Change the value of this parameter and observe what happens.\n",
    "\n",
    "What is the influence of the number of neighbors on the decision function?\n",
    "Select what you view as a 'sensible' value for $k$ (with reasonable tradeoffs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0804f3b44a3f37d224534aa13590b87f",
     "grade": false,
     "grade_id": "cell-f47ed384889fa9ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train_and_plot_knn_regressor(...)\n",
    "# change the value of k_sensible\n",
    "k_sensible = 0\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655cd90be6fc86a91587cf775903e254",
     "grade": true,
     "grade_id": "cell-2dd83a283b07315f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1074743a5d4a3c3505610422ebc25586",
     "grade": false,
     "grade_id": "cell-78b9ebed5aa19c8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider when faced with a very noised dataset (wrong labels, misplaced points, ...), should you increase or decrease $k$? (No answer expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7aedd0ebd126e83152e373c533d1dc69",
     "grade": false,
     "grade_id": "cell-d00e5307bdd62024",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 11\n",
    "\n",
    "Solve the Titanic problem with the k Nearest Neighbors method (see [`lab_session_01`](https://htmlpreview.github.io/?https://github.com/adimajo/CSE204-2021/blob/master/lab_session_01/lab_session_01.html)). Reuse the code of the first lab session:\n",
    "* read the data with `read_csv`;\n",
    "* select the columns useful for prediction;\n",
    "* drop the missing values;\n",
    "* map the categorical columns to numerical values;\n",
    "* split into a training and a test subset;\n",
    "* instantiate a k-NN classifier named `knn_sklearn`;\n",
    "* fit the model (see previous exercises);\n",
    "* compute an accuracy score (ratio of correctly predicted test points) that you store in a `score` variable. Hint: this can be computed by... the eponymous `score` function of `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c9c492addd3e562606cc32f2d00992d",
     "grade": false,
     "grade_id": "cell-c5fa6ac1da40588a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Replace score with your result\n",
    "score = 0\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1a30be67b7d110bf05e1b5bd85ea8f4",
     "grade": true,
     "grade_id": "cell-0a1433f7cba5d0d6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db2881ff19f3857f9ad45ba0dce1803b",
     "grade": false,
     "grade_id": "cell-20a4cf8bfa142bc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 12\n",
    "\n",
    "Write your own implementation for the k Nearest Neighbor algorithm.\n",
    "Write a `knn()` function that takes two arguments:\n",
    "- `xtrain`: the observed dataset;\n",
    "- `ytrain`: the observed labels;\n",
    "- `xpred`: a list of examples to predict;\n",
    "- `n_neighbors`: the number of nearest neighbors to use.\n",
    "\n",
    "This function should return the sequence of predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20a0427834b0cb75a74b2a12af518e51",
     "grade": false,
     "grade_id": "cell-6020f515b3dff121",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "\n",
    "def knn(xtrain, ytrain, xpred, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Predicts the y values of xpred given xtrain, ytrain, and n_neighbors-nn classification\n",
    "\n",
    "    :param pandas.DataFrame xtrain: the training set's features (you can use numpy arrays as well)\n",
    "    :param pandas.DataFrame ytrain: the training set's labels (you can use numpy arrays as well)\n",
    "    :param pandas.DataFrame xpred: the test set's features (you can use numpy arrays as well)\n",
    "    :param int n_neighbors: number of nearest neighbors to use\n",
    "    \"\"\"\n",
    "    # So as not to mess up with the original dataframes\n",
    "    xtrain_cpy = xtrain.copy()\n",
    "    ytrain_cpy = ytrain.copy()\n",
    "    xpred_cpy = xpred.copy()\n",
    "    # Store the distances in a matrix\n",
    "    distances = np.zeros((xtrain_cpy.shape[0], xpred_cpy.shape[0]))\n",
    "    # Store the predictions in a vector\n",
    "    ypred = np.zeros(xpred_cpy.shape[0])\n",
    "    # You might want to reset the index (to have to correct row numbers)\n",
    "    xtrain_cpy.reset_index(inplace=True, drop=True)\n",
    "    xpred_cpy.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # Compute distances of each row x in xtrain to each row x' in xpred and put it in `distances`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Average the labels of the `n_neighbors` closest points in xtrain of each row x in xpred\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcb150fd3624e2457518c7a4cc2a4586",
     "grade": false,
     "grade_id": "cell-e5ea1393e549f5fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# It is assumed you defined X_train, Y_train, X_test in Exercise 11.\n",
    "your_predictions = knn(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c990e7acfc95658d921bbdd47c0c0ab1",
     "grade": false,
     "grade_id": "cell-b99ef79fe1b398a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# It is assumed you \"trained\" knn_sklearn in Exercise 11.\n",
    "sklearn_predictions = knn_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec3362624ec53de8d5a4bef321f5bbfe",
     "grade": false,
     "grade_id": "cell-8d27bcdb4c09a815",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Are the two predictions the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee4b7712f5242404cc28bc11fe09f879",
     "grade": true,
     "grade_id": "cell-d92f3bd4a07ef5a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (your_predictions == sklearn_predictions).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3ff18060336cd2a5a1d241dd631155d",
     "grade": false,
     "grade_id": "cell-782eaecaba9da31a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Computational Complexity\n",
    "\n",
    "Think about the computational complexity of logistic regression vs kNN, in terms of `fit`ting and `predict`ing (for increasing $n$ in the training set).\n",
    "\n",
    "Use the next cell to write some code to perform an experiment and test this to obtain more intuition.\n",
    "\n",
    "Make use of scikit-learn implementations, fit them on a linearly growing training set (for each size, measure the time spent on `fit`ting), and test each of these fitted models on a single point (say, the first sample of training set - for each size, measure the time spent on `predict`ing).\n",
    "\n",
    "N.B.: it could also be very interesting to compare predictive performance (e.g. accuracy).\n",
    "\n",
    "Hint: to measure time, you can use `time.time()` at some point in your code, and then substract this value, at a later point, with the new `time.time()` to obtain a duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ecb93d0513c6c43872e5017409d2bd3",
     "grade": false,
     "grade_id": "cell-63ca41aa588946d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3465bd2609c2395b342c367c1b9f95cc",
     "grade": false,
     "grade_id": "cell-13b883c4bf56d7d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sizes = list(range(100, 10001, 100))\n",
    "\n",
    "\n",
    "def test(clf: sklearn.linear_model.LogisticRegression | sklearn.neighbors.KNeighborsClassifier):\n",
    "    fit_times = []\n",
    "    predict_times = []\n",
    "\n",
    "    clf = sklearn.base.clone(clf)\n",
    "    print(clf)\n",
    "    \n",
    "    for size in sizes:\n",
    "        df = gen_2d_classification_samples(n_samples=size, nclass=2)\n",
    "        # Call time.time()\n",
    "        # Fit the classifier on df\n",
    "        # Store the time it took to fit in fit_time\n",
    "        # Call time.time()\n",
    "        # Predict using the previously fit classifier on THE FIRST SAMPLE of df\n",
    "        # Store the time it took to predict in predict_time\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        fit_times.append(fit_time)\n",
    "        predict_times.append(predict_time)\n",
    "    return fit_times, predict_times\n",
    "\n",
    "lr_fit_times, lr_predict_times = test(sklearn.linear_model.LogisticRegression(penalty=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit_times, knn_predict_times = test(sklearn.neighbors.KNeighborsClassifier(algorithm=\"brute\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e3d45ead5c4b31f85d22b7ca6e14b15",
     "grade": false,
     "grade_id": "cell-0dceb908434a7176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's represent these times on a graph w.r.t. the input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60a4276a117962c48615f4f7c7c68a9a",
     "grade": false,
     "grade_id": "cell-c77f6c1c74eeb0e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.set_ylabel(\"Fit time\")\n",
    "ax2.set_ylabel(\"Predict time\")\n",
    "ax1.plot(sizes, lr_fit_times, label=\"Logistic regression fit time\")\n",
    "ax1.plot(sizes, knn_fit_times, label=\"kNN fit time\")\n",
    "ax2.plot(sizes, lr_predict_times, label=\"Logistic regression predict time\", color='g')\n",
    "ax2.plot(sizes, knn_predict_times, label=\"kNN predict time\", color='r')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a07f444b2a7d67033d9480f54805c05b",
     "grade": false,
     "grade_id": "cell-a91ffdd021281f9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does this confirm your intuitions? Go back and play around with the `algorithm` argument of `KNeighborsClassifier`, see [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n",
    "\n",
    "What relationship can we then assume (or even demonstrate!) between $n$ and `fit` (resp. `predict`) time?\n",
    "\n",
    "Why does the `algorithm` argument of `KNeighborsClassifier` make results change that much, both in terms of `fit` and `predict`? [Hint](https://en.wikipedia.org/wiki/K-d_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
